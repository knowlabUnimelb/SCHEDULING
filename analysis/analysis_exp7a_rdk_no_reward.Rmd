---
title: "Experiment 7a: RDK Direction Judgement, 4 Tasks, Error Penalty (Exp2 Replication)"
author: "knowlabUnimelb"
date: "2022-06-26"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


Sandra Takchi^1^, Ami Eidels^2^, and Daniel R. Little^1^ ^1^ The University of Melbourne, ^2^ The University of Newcastle

```{r TODO, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Ensure code is working

```

```{r load_modules, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
library(tidyverse)
library(workflowr)
#library(Rankcluster)
#library(rankdist) # Crashes rStudio
#library(Kendall)
library(DescTools) # ConDisPairs looks useful
library(gtools) 
library(english)
library(ggplot2)
library(dplyr)
library(hrbrthemes)
library(knitr)
library(reshape2)
library(png)
library(grid)
library(lme4)
library(rstatix)
library(jpeg)
library(pmr)
```

```{r load_data, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
rm(list=ls())

#define working directories
inputdir <- "data"

# Reading data and variable names 
datafilename = "exp7a_rdk_no_reward_data.csv"
colfile       <- read.csv(paste(inputdir,"data_dictionary_rdk_reward.csv",sep="/"), stringsAsFactors = FALSE)
datafn  <- paste(inputdir, datafilename,sep="/") 
rawdata  <- read.csv(datafn, header = FALSE, col.names = colfile$Column, colClasses = colfile$Type, stringsAsFactors = FALSE, na.strings='NA') # Add column labels to data

# If any subjects partially complete the experiment without an id, remove them
# rawdata = rawdata[!is.na(rawdata$uniqueid), ]

# Pilot subjects used id number 9999, remove them
rawdata = rawdata[rawdata$uniqueid != 9999, ]

# Fix some specific information here
rawdata$correct[is.na(rawdata$correct)] = 0 # Incorrect trials were recorded as NA

# Summary data
loggedSubjects = rawdata %>% distinct( uniqueid)
nLoggedSubjects = rawdata %>% distinct( uniqueid) %>% count()

```

```{r data_cleaning, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

# Separate demographic information from data
uncleandata = rawdata[rawdata$trial_event != "demographics", ]

# A full data set has 10 practice trials (0 to 9) and 30 deadline trials (0 to 29)
# A full data set will have a max trial number of 29 
nTotalTrials = 29 # Counting from trial 0

completeSubjects = uncleandata[uncleandata$trial_number == nTotalTrials, ] %>% distinct(subject)
nCompleteSubjects = uncleandata[uncleandata$trial_number == nTotalTrials, ] %>% distinct(subject) %>% count()

# Keep only complete datasets
cleandata = uncleandata[uncleandata$subject %in% completeSubjects$subject, ]

# some subjects may have completed the experiment twice, keep only first completion
completionIds = cleandata %>% distinct(uniqueid, subject)
completionCounts = cleandata %>% distinct(uniqueid, subject) %>% count(uniqueid)
repeatedIds = completionCounts$uniqueid[completionCounts$n > 1]

toDeleteSecondEntry = completionIds[completionIds$uniqueid %in% repeatedIds, ] %>% filter(duplicated(uniqueid))
keeplist = anti_join(completionIds, toDeleteSecondEntry)

# keep only nonrepeated subs
cleandata = cleandata[cleandata$subject %in% keeplist$subject, ]
subjects = cleandata %>% distinct(uniqueid)
nSubjects = cleandata %>% distinct(uniqueid) %>% count()

```

```{r add_phase_col, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

# Add in phase column which indicates whether current trials are practice or experiment
add_phase_col = function(data, subs){
  nSubs = length(subs)
  data$phase = rep(NA, nrow(data))
  for (i in 1:nSubs){
    
    # Find point at which trial_index = 0 later in the trial
    tidx = which(data$trial_number[data$uniqueid == subs[i]] == 0)
    idx = tidx[which(diff(tidx) > 1) + 1]
    
    dsize = nrow(data[data$uniqueid == subs[i], ])
    data$phase[data$uniqueid == subs[i]] = c(rep(0, idx-1), rep(1,length(idx:dsize)))
  }
  return(data)
}
cleandata = add_phase_col(cleandata, subjects$uniqueid)
cleandata$phase = as.factor(cleandata$phase)
levels(cleandata$phase) = c("untimed", "deadline")


```

```{r emails, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Need to extract emails for sending results from all datasets
# Turned off due to ethics

demographics = rawdata[rawdata$trial_event == "demographics", ]
#emails = demographics[grep("Email", demographics)]
#colon_loc = gregexpr(pattern = ":", emails)
#full_email_list = rep(NA, nSubjects)
#for (i in 1:nSubjects){
#  if (!is.na(emails[i])){
#    full_email_list[i] = substr(emails[i], colon_loc[[i]][1]+2, nchar(emails[i])-2)
#  }
#}
#email_list = str_sort(full_email_list[full_email_list != "" & !is.na(full_email_list)])

```

```{r demographics, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Demographics
# trial_event = sex_age
# responses --> Gender and Age

sexage = demographics$responses[grep("Gender", demographics$responses)]
  
colon_loc = gregexpr(pattern = ":", sexage)
comma_loc = gregexpr(pattern = ",", sexage)

nSubs = sum(nSubjects$n)  
sex = rep(NA, nSubs)
age = rep(NA, nSubs)
for (i in 1:nSubs){
  sex[i] = toupper(substr(sexage[i], colon_loc[[i]][1]+2, comma_loc[[i]][1]-2))
  
  x = substr(sexage[i], colon_loc[[i]][2]+2, nchar(sexage[i])-2)
  if (nchar(x) == 2){
    age[i] = as.numeric(x)
  } else {
    age[i] = as.numeric(substr(sexage[i], colon_loc[[i]][2]+2, colon_loc[[i]][2]+4))    
  }
}

demo_data = subjects %>% mutate(age, sex)  

nFemales = demo_data %>% filter(sex == "FEMALE " | sex == "FEMALE" | sex == "WOMEN" | sex == "WOMAN") %>% distinct(uniqueid) %>% count()
nMales   = demo_data %>% filter(sex == "MAN" | sex == "MALE") %>% distinct( uniqueid) %>% count()
nUnspec  = demo_data %>% filter(sex != "FEMALE" & sex != "WOMEN" & sex != "MALE" & sex != "FEMALE " & sex != "WOMAN" & sex != "MAN") %>% distinct( uniqueid) %>% count()
 
meanAge = demo_data %>% group_by() %>% summarise(mean = mean(age, na.rm = TRUE))
stdAge = demo_data %>% group_by() %>% summarise(sd = sd(age, na.rm = TRUE))

```

# Method

## Participants

47 participants were recruited for the experiment, 38 of which were female and 9 males. The participants were first year psychology students who did the experiment to earn extra credits for their course. Their age ranged between 17 and 33. 

[SANDRA TO UPDATE THIS SECTION]

## Design

```{r getCoherenceSet, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Get all coherence options
# .8 = Easy, .5 = Medium, .2 = Hard, .0 = Very hard
coherence_set = sort(unique(c(cleandata$patch_0, cleandata$patch_1, cleandata$patch_2, cleandata$patch_3)), decreasing = TRUE)

```

In this experiment, participants will complete multiple trials for selecting and completing random dot kinematogram (RDK) tasks. On each trial, participants will be shown a set of four RDKs labelled Easy,Medium, Hard, and Very Hard. The labels correspond to the difficulty of the RDK instantiated by the proportion of dots moving in a coherent direction. Participants will select and complete one RDK at a time,in any order, completing as many as possible before a deadline.Before completing the deadline task, participants will complete 10 trials with no deadline. This will help participants learn the task, explore strategies, and allow us to compare the optimality of responding between a no deadline and a deadline condition (Little, 202).

*Data Cleaning*

Subjects completed the experiment by clicking a link with the uniquely generated id code. They were able to use the link multiple times; further, subjects were able to exit the experiment at any time. Consequently, the datafile contains partially completed data for some subjects which needed to be identified and removed.

```{r analyse_RDK_difficulty, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Get rdk data
rdk = cleandata %>% filter(trial_event == 'rdk')

# Total rdk timeouts
nTimeouts = rdk %>% filter(rt == -1) %>% count()
pTimeouts = nTimeouts$n/nrow(rdk)

# Timeouts by subject
timeoutsPerSubject = rdk %>% filter(rt == -1) %>% count(uniqueid)
avgTimeoutPerSubject = mean(timeoutsPerSubject$n)

# Remove rdk timeouts
rdk = rdk %>% filter(rt != -1) 

# Analyse long rts
longRTcutoff = 3000
nlongrts = rdk %>% filter(rt > longRTcutoff) %>% count(phase)

# Remove long rts: Note: I've turned off the removal of longrts. I think we can safely keep these in
# rdk = rdk %>% filter(rt <= longRTcutoff)

```

```{r identify_nonlearners, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

easyacc = rdk %>% filter(dot_coherence == .8) %>% group_by(phase, uniqueid) %>% summarise(mean = mean(correct))
nonlearners = easyacc %>% filter(mean < .4)
nNonlearners = nonlearners$uniqueid %>% unique() %>% length()

# Remove nonlearners
data = cleandata %>% filter(!uniqueid %in% nonlearners$uniqueid)
rdk = rdk %>% filter(!uniqueid %in% nonlearners$uniqueid)

# Count remaining subjects
finalSubjects = data %>% distinct(condition, uniqueid)
final_n = data %>% distinct(condition, uniqueid) %>% count(condition)

```

Non-learners are participants who were unable to do the easiest task presented in the experiment. In other words, they were unable to make a judgment on whether the dots in the RDK were moving to the left or right.

```{r task_completion, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# tcdata = aggregate(rdk$trial_event[rdk$correct == 1], by=list("condition" = rdk$condition[rdk$correct == 1], "trial" = rdk$trial_number[rdk$correct == 1], "phase" = rdk$phase[rdk$correct == 1], "subject" = rdk$uniqueid[rdk$correct == 1]), FUN=length)

tcdata = rdk %>% filter(correct == 1) %>% group_by(trial_number, phase, uniqueid) %>% count()
avgCompletions = rdk %>% filter(correct == 1) %>% group_by(trial_number, phase, uniqueid) %>% count() %>% group_by(phase) %>% summarise(mean = mean(n, na.rm=TRUE))

# Need to run stats to compare number of task completions in each phase
avgSubCompletions = tcdata %>% group_by(uniqueid, phase) %>% summarize(mean = mean(n, n.rm=TRUE))
tc.aov = aov(mean ~ phase, data = avgSubCompletions)
summary(tc.aov)

```

# Data Analysis

We first summarize performance by answering the following questions:

## Task completions

-   How many tasks are completed on average?



```{r task_completion_table, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Reorder columns
avgCompletions = avgCompletions[c("phase", "mean")]
kable(avgCompletions, caption="Average number of correctly completed tasks in each condition")
```

In the untimed phase, participants completed 3.9 tasks on average, whereas, in the deadline phase, they completed 3.3 tasks on average. This means that they were able to complete almost all the tasks when not under time pressure, but completed almost only 3/4 when constrained with a deadline.

## RDK performance

```{r rdk_anova, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# TODO: Rewrite using tidyverse
aov.acc.data = aggregate(list("accuracy" = rdk$correct), by = list("subject" = rdk$uniqueid, "phase" = rdk$phase, "difficulty" = rdk$dot_coherence), FUN = function(x) mean(x, na.rm=TRUE))

aov.rt.data = aggregate(list("rt" = rdk$rt), by = list("subject" = rdk$subject, "phase" = rdk$phase, "difficulty" = rdk$dot_coherence), FUN = function(x) mean(x, na.rm=TRUE))

# Note that RT is computed by averaging every attempt
# Another way to compute RT is by summing over incorrect attempts until the RDK is responded to correctly

rdk.crt = aggregate(list("crt" = rdk$rt), by = list("subject"=rdk$subject, "phase"=rdk$phase, "difficulty"=rdk$dot_coherence, "trial"=rdk$trial_number), FUN = function(x) tail(cumsum(x), n=1))

# rdk.crt = rdk.crt[rdk.crt$crt <= 6000, ]

aov.crt.data = aggregate(list("rt" = rdk.crt$crt), by = list("subject" = rdk.crt$subject,  "phase" = rdk.crt$phase, "difficulty" = rdk.crt$difficulty), FUN = function(x) mean(x, na.rm=TRUE))

#anova.acc = glm(accuracy ~ condition + phase + difficulty + condition:phase:difficulty, aov.acc.data, family = "gaussian")
#anova.rt = glm(rt ~ condition + phase + difficulty + condition:phase:difficulty, aov.rt.data, family = "gaussian")


anova.acc = anova_test(data = aov.acc.data, dv = accuracy, wid = subject, within = c(phase, difficulty))
anova.rt = anova_test(data = aov.rt.data, dv = rt, wid = subject, within = c(phase, difficulty))
anova.crt = anova_test(data = aov.crt.data, dv = rt, wid = subject, within = c(phase, difficulty))

# Linear contrasts
aov.acc.data.linear <- aov.acc.data %>%
  mutate(diffnum = difficulty %>% recode(`0.0` = 3, `0.2` = 2, `0.5` = 1, `0.8` = 0),
         linear = diffnum %>% recode(`0` = -3, `1` = -1, `2` = 1, `3` = 3))
contrasts.acc <- lm(accuracy ~ linear + subject, data = aov.acc.data.linear)
summary(contrasts.acc)

aov.acc.data.linear <- aov.acc.data %>%
  mutate(diffnum = difficulty %>% recode(`0.0` = 3, `0.2` = 2, `0.5` = 1, `0.8` = 0),
         linear = diffnum %>% recode(`0` = -3, `1` = -1, `2` = 1, `3` = 3))
contrasts.acc <- lm(accuracy ~ linear + subject, data = aov.acc.data.linear)
summary(contrasts.acc)

aov.rt.data.linear <- aov.rt.data %>%
  mutate(diffnum = difficulty %>% recode(`0.0` = 3, `0.2` = 2, `0.5` = 1, `0.8` = 0),
         linear = diffnum %>% recode(`0` = -3, `1` = -1, `2` = 1, `3` = 3))
contrasts.rt <- lm(rt ~ linear + subject, data = aov.rt.data.linear)
summary(contrasts.rt)

aov.crt.data.linear <- aov.crt.data %>%
  mutate(diffnum = difficulty %>% recode(`0.0` = 3, `0.2` = 2, `0.5` = 1, `0.8` = 0),
         linear = diffnum %>% recode(`0` = -3, `1` = -1, `2` = 1, `3` = 3))
contrasts.crt <- lm(rt ~ linear + subject, data = aov.crt.data.linear)
summary(contrasts.crt)


```

We next analysed performance on the RDK discriminations. We then asked:

-   What was the average completion time and accuracy of the easy, medium, hard, and very hard tasks?

```{r difficulty_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

# Difficulty plot
rdk$labels = factor(rdk$dot_coherence)
levels(rdk$labels) = c("v. hard", "hard", "medium", "easy")
rdk$labels = reorder(rdk$labels, new.order = c("easy", "medium", "hard", "v. hard"))

# Trim long tails on violin plot
pct = quantile(rdk$rt, c(.025, .975))
trim_rdk = rdk %>% filter(rt > pct[1] & rt < pct[2])

diff_plot <- trim_rdk %>% ggplot(aes(x=labels, y=rt, fill=labels)) + geom_violin(adjust = 1.5, trim = TRUE, scale="area") + facet_wrap(~phase) + labs(y="RT (msec)", x = "Difficulty")
print(diff_plot + ggtitle("Response times as a function of difficulty"))
```

As shown in the figure, RT increased as difficulty increased. 

```{r difficulty_sum_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# RT summed over additional attempts
rdk.crt$labels = as.factor(rdk.crt$difficulty)
levels(rdk.crt$labels) = c("v. hard", "hard", "medium", "easy")
rdk.crt$labels = reorder(rdk.crt$labels, new.order = c("easy", "medium", "hard", "v. hard"))

# Trim long tails on violin plot
spct = quantile(rdk.crt$crt, c(.025, .975))
trim_crdk = rdk.crt %>% filter(crt > spct[1] & crt < spct[2])

crt_diff_plot <- trim_crdk %>% ggplot(aes(x=labels, y=crt, fill=labels)) + geom_violin(adjust = 1.5, trim = TRUE, scale="area") + facet_wrap(~phase) + labs(y="RT (msec)", x = "Difficulty")
print(crt_diff_plot + ggtitle("Response times summed over attempts as a function of difficulty"))

```

We further broke down RTs by condition, deadline, and difficulty.

```{r difficulty_data, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# TODO: recode to tidyverse
# Find average rdk accuracy and rt in each codnition, phase, and coherence level
difficulty = aggregate(list("accuracy" = rdk$correct, "rt" = rdk$rt), by = list("difficulty" =  rdk$labels, "phase" = rdk$phase), FUN = function(x) mean(x, na.rm = TRUE))
sum_difficulty = aggregate(list("crt" = rdk.crt$crt), by = list("difficulty" = rdk.crt$labels, "phase" = rdk.crt$phase), FUN = function(x) mean(x, na.rm = TRUE))
                
diffsd = aggregate(list("accuracy" = rdk$correct, "rt" = rdk$rt), by = list("difficulty" = rdk$labels, "phase" = rdk$phase), FUN = function(x) sd(x, na.rm = TRUE))
sum_diffsd = aggregate(list("crt" = rdk.crt$crt), by = list("difficulty" =  rdk.crt$labels, "phase" = rdk.crt$phase), FUN = function(x) sd(x, na.rm = TRUE))

ncounts = rdk %>% count(phase, dot_coherence)
difficulty$n = ncounts$n
difficulty$accuracy = round(difficulty$accuracy, 2)
difficulty$rt = round(difficulty$rt, 2)
difficulty$se.acc = diffsd$accuracy/sqrt(difficulty$n)
difficulty$se.acc = round(difficulty$se.acc, 2)
difficulty$se.rt = diffsd$rt/sqrt(difficulty$n)
difficulty$se.rt = round(difficulty$se.rt, 2)
difficulty$crt = round(sum_difficulty$crt, 2)
difficulty$se.crt = sum_diffsd$crt/sqrt(difficulty$n)
difficulty$se.crt = round(difficulty$se.crt, 2)


difficulty$difficulty = as.factor(difficulty$difficulty)
#levels(difficulty$difficulty) = c("Very Hard", "Hard", "Medium", "Easy")
```


## Reward Rate

[ADD  DESCRIPTION]

```{r rewardRate_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

# Get reward rate standard error
rrdata = aggregate(list("accuracy" = rdk$correct), by = list("difficulty" = rdk$labels, "phase" = rdk$phase, "subject"=rdk$subject), FUN = function(x) mean(x, na.rm = TRUE))
rrdata_crt = aggregate(list("crt" = rdk.crt$crt), by = list("difficulty" = rdk.crt$labels, "phase" = rdk.crt$phase, "subject"=rdk.crt$subject), FUN = function(x) mean(x, na.rm = TRUE))

# Average score (letter match) values for easy, med, hard, and very hard tasks
# computed from generateWordleClues_matchToTarget.m
rewardscores = c(1, 1, 1, 1)
rrdata$score[rrdata$difficulty == 'easy'] = rewardscores[1]
rrdata$score[rrdata$difficulty == 'medium'] = rewardscores[2]
rrdata$score[rrdata$difficulty == 'hard'] = rewardscores[3]
rrdata$score[rrdata$difficulty == 'v. hard'] = rewardscores[4]

rrdata$crt = rrdata_crt$crt
rrdata$rewardRate = rrdata$score*rrdata$accuracy/(rrdata$crt/1000)

subRewardRate = aggregate(list("rr" = rrdata$rewardRate), by = list("difficulty" =  rrdata$difficulty, "phase" = rrdata$phase), FUN = function(x) mean(x, na.rm = TRUE))

subRewardRate.se = aggregate(list("rr" = rrdata$rewardRate), by = list("difficulty" =  rrdata$difficulty, "phase" = rrdata$phase), FUN = function(x) sd(x, na.rm = TRUE))

difficulty$rewardRate = subRewardRate$rr
difficulty$SE.rewardRate = subRewardRate.se$rr/sqrt(difficulty$n)

rr_plot <- rrdata %>% ggplot(aes(x=difficulty, y=rewardRate, fill=difficulty)) + geom_violin(adjust = 1, trim = TRUE, scale = "width") + geom_jitter(height = 0, width = 0.1) +  stat_summary(fun=mean, geom="point", shape=23, size=2) + facet_wrap(~phase) + labs(y="Reward Rate = Reward*p(Correct)/RT(sec)", x = "Difficulty") + lims(y = c(0, 4.5))

print(rr_plot + ggtitle("Reward Rate as a function of difficulty"))

anova.rr = anova_test(data = rrdata, dv = rewardRate, wid = subject, within = c(phase, difficulty))
print(anova.rr)

bonfTest = pairwise.t.test(rrdata$rewardRate,  paste(rrdata$difficulty, rrdata$phase), p.adjust.method = "bonf")
print(bonfTest)

```


## Optimality in each condition

-   What is the proportion of easy, medium, hard, and very hard tasks selected first, second, third or fourth? 

```{r get_selections, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
numberOfTasks = 4 # Number of tasks

selection_data = data %>% filter(trial_event %in% c("practice_rdk", "select_rdk"))
selection_data$trial_event = droplevels(selection_data$trial_event) # drop demographics level

ph = c(rep("untimed", 10), rep("deadline", 30))
cn = c(rep("practice_rdk", 10), rep("select_rdk", 30))
tr = c(seq(0,9), seq(0,29))
sdLength = length(cn) # selection data length for each subject

# Convert location selections to difficulty order selections
selections = data.frame(subject = rep(finalSubjects$uniqueid, each = sdLength), condition = rep(finalSubjects$condition, each = sdLength), phase = rep(ph, sum(final_n$n)), trial = rep(tr, sum(final_n$n)), selected_difficulty_1 = rep(NA, sum(final_n$n) * sdLength), selected_difficulty_2 = rep(NA, sum(final_n$n) * sdLength), selected_difficulty_3 = rep(NA, sum(final_n$n) * sdLength), selected_difficulty_4 = rep(NA, sum(final_n$n) * sdLength), rt_1 = rep(NA, sum(final_n$n) * sdLength), rt_2 = rep(NA, sum(final_n$n) * sdLength), rt_3 = rep(NA, sum(final_n$n) * sdLength), rt_4 = rep(NA, sum(final_n$n) * sdLength))
selections$phase <- factor(selections$phase, levels = c("untimed", "deadline"))


cnt = 1
total = sum(final_n$n) * sdLength
pb <- txtProgressBar(min = 0, max = total, style = 3)
for (i in 1:sum(final_n$n)){
    for (j in 1:sdLength){
      # Coherence in each location (W, N, E, S) 
      coherence_locations = selection_data %>% filter(uniqueid == finalSubjects$uniqueid[i], trial_event == cn[j], trial_number == tr[j]) %>% slice(1) %>% select(patch_0, patch_1, patch_2, patch_3)
      
      difficulty_selections = selection_data %>% filter(uniqueid == finalSubjects$uniqueid[i], trial_event == cn[j], trial_number == tr[j]) %>% pull(selected_difficulty) + 1

      # coherence_selections = as.numeric(as.vector(coherence_locations)[location_selections[!is.na(location_selections)]])
      # length(coherence_selections) <- numberOfTasks # pad end with NAs
      
      selection_rt = selection_data %>% filter(uniqueid == finalSubjects$uniqueid[i], trial_event == cn[j], trial_number == tr[j]) %>% pull(rt)
      length(selection_rt) <- numberOfTasks # pad end with NAs
      
      selections$selected_difficulty_1[cnt] = difficulty_selections[1]
      selections$selected_difficulty_2[cnt] = difficulty_selections[2]
      selections$selected_difficulty_3[cnt] = difficulty_selections[3]
      selections$selected_difficulty_4[cnt] = difficulty_selections[4]
      
      selections$rt_1[cnt] = selection_rt[1]
      selections$rt_2[cnt] = selection_rt[2]
      selections$rt_3[cnt] = selection_rt[3]
      selections$rt_4[cnt] = selection_rt[4]

      cnt = cnt + 1
      setTxtProgressBar(pb, cnt)
    }
}
close(pb)

selections$rt_1[selections$rt_1 < 0] = NA
selections$rt_2[selections$rt_2 < 0] = NA
selections$rt_3[selections$rt_3 < 0] = NA
selections$rt_4[selections$rt_4 < 0] = NA

```

```{r find_heatmap, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
fixed_untimed   = selections %>% filter(phase == "untimed") %>% select(selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4) %>% as.matrix()
fixed_deadline  = selections %>% filter( phase == "deadline") %>% select(selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4) %>% as.matrix()


imputeMissingData = function(data, n = numberOfTasks){
  for (i in 1:n){
      data[is.na(data[,i]), i] = mean(data[,i], na.rm=TRUE)
  }
  return(data)
}

fixed_untimed = imputeMissingData(fixed_untimed, numberOfTasks)
fixed_deadline = imputeMissingData(fixed_deadline, numberOfTasks)


fu = fixed_untimed %>% rankagg() %>% destat()
fd = fixed_deadline %>% rankagg() %>% destat()

```

```{r heatmap_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

# Convert to proportions
setUpMat = function(matData){
  mat = t(apply(matData, 1, function(x) x/sum(x)))  
  matMelt = melt(mat)
  names(matMelt) = c("Difficulty", "Order", "value")
  return(matMelt)
}
fumelt = setUpMat(fu$mar)
fdmelt = setUpMat(fd$mar)

hm = rbind(cbind("condition" = rep("Untimed", nrow(fumelt)), fumelt), 
           cbind("condition" = rep("Deadline", nrow(fdmelt)), fdmelt))
hm$condition = factor(hm$condition, levels = c("Untimed", "Deadline"))

hmplot = ggplot(hm, aes(x=Difficulty, y=Order)) +
          geom_tile(aes(fill=value)) +
          scale_fill_gradientn(colours=c("blue","pink", "red")) +
          geom_text(aes(label=round(value, 2))) + 
          scale_y_reverse() +
          facet_wrap(~condition) + 
          labs(y="Selection", x = "Difficulty")
print(hmplot)

```
Participants started with the easiest task first (68%) and ended with the hardest task (49%) when the task was untimed. When the deadline was introduced, participants tended to be more optimal, and the percentage of choosing the easiest first increased to 83% and choosing the hardest last to 82%. This suggests that people are more optimal when under time pressure. 


-   Do the marginal distributions differ from uniformity?

We tested whether the marginal distributions were different from uniformally random selection using the fact that the mean rank is distributed according to a $\chi^2$ distribution with the following test-statistic: $$\chi^2 = \frac{12N}{k(k+1)}\sum_{j=1}^k \left(m_j - \frac{k+1}{2} \right)^2$$ see s(Marden, 1995).

```{r chi2uniformity, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
selection_n = selections %>% count(phase) 

# Compare heatmaps to uniform
observed <- fu$mean.rank

chi2UniformRank = function(observed, n, k = numberOfTasks){
  ex <- rep((k + 1)/2, k);
  oc <- observed
  
  chi = (12 * n/(k * (k + 1))) * sum((oc - ex)^2) # Test statistic of mean rank under uniformity
  p = dchisq(chi, k-1)
  return(list("chi2" = chi, "chi2p" = p))
}

fu$uni <- chi2UniformRank(fu$mean.rank, selection_n$n[selection_n$phase == "untimed"])
fd$uni <- chi2UniformRank(fd$mean.rank, selection_n$n[selection_n$phase == "deadline"])

chiUniformTable = data.frame("phase" = c("untimed", "deadline"), 
                            "chi2" = round(c(fu$uni$chi2, fd$uni$chi2),2), 
                            "df" = c(3,3),
                            "p" = round(c(fu$uni$chi2p, fd$uni$chi2p), 2))

knitr::kable(chiUniformTable, caption = "Chi2 test of uniformity")

```

[ADD DESCRIPTION]

We compared the location conditions and phases using chi-2 analysis.

```{r chi2btw, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Compare heatmaps to each other
chi2_f_UvsD = chisq.test(cbind(as.vector(fu$mar),as.vector(fd$mar))) # Untimed vs Deadline

chi2compTable = data.frame("Comparison" = c("Untimed vs Deadline"), 
                           "chi2" = round(c(chi2_f_UvsD$statistic), 2),
                           "df" = c(chi2_f_UvsD$parameter),
                           "p"  = round(c(chi2_f_UvsD$p.value), 2))

knitr::kable(chi2compTable, caption = "Pearson's chi-squared test")


# MANOVA-like analysis to compare multiple groups? (Marsden book)

```

```{r distcomp, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Distance parameters
maxdistance = (numberOfTasks * (numberOfTasks-1))/2
missing_penalty = maxdistance/numberOfTasks
allperms = permutations(n=4, r=4, v=1:4, repeats.allowed=FALSE)
nperms = nrow(allperms)

# Compute distance from optimal for all perms
pdist <- rep(NA, nperms)
for (i in 1:nperms){
  distObj = ConDisPairs(table(allperms[i, ], c(1,2,3,4)))
  pdist[i] = distObj$D  
}

# Find average distance based on all partial matches
scorePartialMatches = function(sv, allperms, pdist){
    selVector = as.numeric(sv)
    if (all(is.na(selVector))){ # If no tasks are selected
      avgd = mean(pdist)
    } else {
      if (sum(!is.na(selVector)) > 1){ # If more than one task is selected
        dvec = pdist[apply(t(replicate(nperms, selVector[!is.na(selVector)])) == allperms[, !is.na(selVector)], 1, function(x)all(x))]
      } else { # If only one task is selected
        dvec = pdist[selVector[!is.na(selVector)] == allperms[, !is.na(selVector)]]
      }
      avgd = mean(dvec)
    }
    return(list("avgD" = avgd))
}

# Add average distance column
selections = selections %>% mutate("avgD" = apply(selections %>% select(selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4), 1, function(x)(scorePartialMatches(x, allperms, pdist)$avgD)))


```

```{r dist_analysis, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Compare distributions of distances from optimal
dist_fuVSfd = ks.test(selections %>% filter(phase == "untimed") %>% pull(avgD), selections %>% filter(phase == "deadline") %>% pull(avgD))


ksCompTable = data.frame("Comparison" = c("Untimed vs Deadline"), 
                           "ks" = round(c(dist_fuVSfd$statistic), 2),
                           "p"  = round(c(dist_fuVSfd$p.value), 2))

knitr::kable(ksCompTable, caption = "Kolmolgorov-Smirnoff test")

```

-   How optimal were responses?

```{r plotData, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

avg_plot <- selections %>% ggplot(aes(x=avgD, fill=phase)) + geom_histogram(aes(y=..density..), color="white", alpha=0.6, bins = 6, position="identity") + facet_wrap(~phase) + labs(y="Probability", x = "Avg Distance")
print(avg_plot + ggtitle("Avg Distance from Optimal Order"))

```
Participants were optimal in prioritizing the subtasks by difficulty, and this optimality was even more prominent in the task that had a deadline, compared to the untimed task.


<!-- -   How consistent were responses with an easy to hard ordering? -->
<!-- ```{r plotData_eh, echo=FALSE, warning=FALSE, message=FALSE, results="asis"} -->

<!-- avg_plot_eh <- selections %>% ggplot(aes(x=avgD_eh, fill=phase)) + geom_histogram(aes(y=..density..), color="white", alpha=0.6, bins = 6, position="identity") + facet_wrap(~phase) + labs(y="Probability", x = "Avg Distance") -->
<!-- print(avg_plot_eh + ggtitle("Avg Distance from Easy to Hard Order")) -->

<!-- ``` -->

```{r detectMissingSelectionData, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Cycle through every trial, from every subject, from each phase, of every condition 
# Determine if the recorded RDK data matches the selection data
conditions = c("no_reward")
phases = c("untimed", "deadline")
max_trials = c(9, 29) # number of trials in the untimed and deadline conditions
# finalSubjects - list of final subject numbers (uniqueIDs)


udata <- data %>% filter(phase == "untimed")
ddata <- data %>% filter(phase == "deadline")


troubleMakers = setNames(data.frame(matrix(ncol = 4, nrow = 0)), c("condition", "uniqueid", "phase", "trial_number"))
rcnt= 1;

cnt = 1
total = sum(final_n$n) * 10
pb <- txtProgressBar(min = 0, max = total, style = 3)
# Cycle through untimed data first
for (i in 1:sum(final_n$n)){
  # Extract subject data
  sdata <- udata %>% filter(uniqueid == finalSubjects$uniqueid[i])
  
  for (j in 0:max_trials[1]){
    # Extract trial data
    tdata <- sdata %>% filter(trial_number == j)
    
    nSelectionEvents = tdata %>% filter(trial_event == "practice_rdk") %>% count()
    nRdkEvents = tdata %>% filter(trial_event == "rdk") %>% select(dot_coherence) %>% unique() %>% count()
    
    if (nRdkEvents <= nSelectionEvents){ # do nothing
    } else {
      # Add current subject, condition, phase, and trial to the list of troublesome trials      
      troubleMakers[rcnt, ] = c(tdata$condition[1], tdata$uniqueid[1], tdata$phase[1], tdata$trial_number[1])
      rcnt = rcnt + 1
    }
  
  cnt = cnt + 1
  setTxtProgressBar(pb, cnt)
  }
}


cnt = 1
total = sum(final_n$n) * 30
pb <- txtProgressBar(min = 0, max = total, style = 3)
# Cycle through untimed data first
for (i in 1:sum(final_n$n)){
  # Extract subject data
  sdata <- ddata %>% filter(uniqueid == finalSubjects$uniqueid[i])
  
  for (j in 0:max_trials[2]){
    # Extract trial data
    tdata <- sdata %>% filter(trial_number == j)
    
    nSelectionEvents = tdata %>% filter(trial_event == "select_rdk") %>% count()
    nRdkEvents = tdata %>% filter(trial_event == "rdk") %>% select(dot_coherence) %>% unique() %>% count()
    
    if (nRdkEvents <= nSelectionEvents){ # do nothing
    } else {
      # Add current subject, condition, phase, and trial to the list of troublesome trials      
      troubleMakers[rcnt, ] = c(tdata$condition[1], tdata$uniqueid[1], tdata$phase[1], tdata$trial_number[1])
      rcnt = rcnt + 1
    }
  
  cnt = cnt + 1
  setTxtProgressBar(pb, cnt)
  }
}

```
