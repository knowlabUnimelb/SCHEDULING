---
title: "2022 Schedule RT - Experiment 8b: Labelled Word List Typing, 4 Tasks - Wordle Reward"
author: "knowlabUnimelb"
date: "2022-04-10"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

Asha Bartlett^1^, Ami Eidels^2^, and Daniel R. Little^1^
^1^ The University of Melbourne, ^2^ The University of Newcastle

```{r TODO, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# ANOVA Typing Data
# Set up typing_reward analysis

```

```{r load_modules, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
library(tidyverse)
library(workflowr)
#library(Rankcluster)
#library(rankdist) # Crashes rStudio
#library(Kendall)
library(DescTools) # ConDisPairs looks useful
library(gtools) 
library(english)
library(ggplot2)
library(dplyr)
library(hrbrthemes)
library(knitr)
library(reshape2)
library(png)
library(grid)
library(lme4)
library(rstatix)
library(jpeg)
library(pmr)
```

```{r load_data, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
rm(list=ls())
#dev.off(dev.list()["RStudioGD"])

#define working directories
inputdir <- "data"

# Reading data and variable names 
datafilename = "exp8b_typing_reward_data.csv"
colfile       <- read.csv(paste(inputdir,"data_dictionary_typing_reward.csv",sep="/"), stringsAsFactors = FALSE)
datafn  <- paste(inputdir, datafilename,sep="/") 
rawdata  <- read.csv(datafn, header = FALSE, col.names = colfile$Column, colClasses = colfile$Type, stringsAsFactors = FALSE, na.strings='NA') # Add column labels to data

# If any subjects partially complete the experiment without an id, remove them
# rawdata = rawdata[!is.na(rawdata$uniqueid), ]

# Pilot subjects used id number 9999, remove them
rawdata = rawdata[rawdata$unique_id != 9999, ]

# Summary data
loggedSubjects = rawdata %>% distinct( unique_id)
nLoggedSubjects = rawdata %>% distinct( unique_id) %>% count()

```

```{r data_cleaning, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

# Separate demographic information from data
uncleandata = rawdata[rawdata$trial_event != "demographics", ]

# A full data set has 10 practice trials (0 to 9) and 30 deadline trials (0 to 29)
# A full data set will have a max trial number of 29 
nTotalTrials = 29 # Counting from trial 0

completeSubjects = uncleandata[uncleandata$trial_number == nTotalTrials, ] %>% distinct(start_date)
nCompleteSubjects = uncleandata[uncleandata$trial_number == nTotalTrials, ] %>% distinct(start_date) %>% count()

# Keep only complete datasets
cleandata = uncleandata[uncleandata$start_date %in% completeSubjects$start_date, ]

# some subjects may have completed the experiment twice, keep only first completion
completionIds = cleandata %>% distinct(unique_id, start_date)
completionCounts = cleandata %>% distinct(unique_id, start_date) %>% count(unique_id)
repeatedIds = completionCounts$unique_id[completionCounts$n > 1]

toDeleteSecondEntry = completionIds[completionIds$unique_id %in% repeatedIds, ] %>% filter(duplicated(unique_id))
keeplist = anti_join(completionIds, toDeleteSecondEntry)

# keep only nonrepeated subs
cleandata = cleandata[cleandata$start_date %in% keeplist$start_date, ]
subjects = cleandata %>% distinct(unique_id)
nSubjects = cleandata %>% distinct(unique_id) %>% count()

```

```{r add_phase_col, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

# Add in phase column which indicates whether current trials are practice or experiment
add_phase_col = function(data, subs){
  nSubs = length(subs)
  data$phase = rep(NA, nrow(data))
  for (i in 1:nSubs){
    # Find point at which trial_index = 0 later in the trial
    tidx = which(data$trial_number[data$unique_id == subs[i]] == 0)
    idx = tidx[which(diff(tidx) > 1) + 1]
    
    dsize = nrow(data[data$unique_id == subs[i], ])
    data$phase[data$unique_id == subs[i]] = c(rep(0, idx-1), rep(1,length(idx:dsize)))
  }
  return(data)
}
cleandata = add_phase_col(cleandata, subjects$unique_id)
cleandata$phase = as.factor(cleandata$phase)
levels(cleandata$phase) = c("untimed", "deadline")


```

```{r emails, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Need to extract emails for sending results from all datasets
# Turned off due to ethics

demographics = rawdata[rawdata$trial_event == "demographics", ]
#emails = demographics[grep("Email", demographics)]
#colon_loc = gregexpr(pattern = ":", emails)
#full_email_list = rep(NA, nSubjects)
#for (i in 1:nSubjects){
#  if (!is.na(emails[i])){
#    full_email_list[i] = substr(emails[i], colon_loc[[i]][1]+2, nchar(emails[i])-2)
#  }
#}
#email_list = str_sort(full_email_list[full_email_list != "" & !is.na(full_email_list)])

```

```{r demographics, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Demographics
# trial_event = sex_age
# responses --> Gender and Age

sexage = demographics$responses[grep("Gender", demographics$responses)]
  
colon_loc = gregexpr(pattern = ":", sexage)
comma_loc = gregexpr(pattern = ",", sexage)

nSubs = sum(nSubjects$n)  
sex = rep(NA, nSubs)
age = rep(NA, nSubs)
for (i in 1:nSubs){
  sex[i] = toupper(substr(sexage[i], colon_loc[[i]][1]+2, comma_loc[[i]][1]-2))
  
  x = substr(sexage[i], colon_loc[[i]][2]+2, nchar(sexage[i])-2)
  if (nchar(x) == 2){
    age[i] = as.numeric(x)
  } else {
    age[i] = as.numeric(substr(sexage[i], colon_loc[[i]][2]+2, colon_loc[[i]][2]+4))    
  }
}

demo_data = subjects %>% mutate(age, sex)  

nFemales = demo_data %>% filter(sex == "FEMALE " | sex == "FEMALE" | sex == "WOMEN" | sex == "WOMAN") %>% distinct(unique_id) %>% count()
nMales   = demo_data %>% filter(sex == "CISGENDER MALE" | sex == "MAN" | sex == "MALE") %>% distinct( unique_id) %>% count()
nUnspec  = demo_data %>% filter(sex != "FEMALE" & sex != "WOMEN" & sex != "MALE" & sex != "FEMALE " & sex != "WOMAN" & sex != "MAN") %>% distinct( unique_id) %>% count()
 
meanAge = demo_data %>% group_by() %>% summarise(mean = mean(age, na.rm = TRUE))
stdAge = demo_data %>% group_by() %>% summarise(sd = sd(age, na.rm = TRUE))

```
# Method

## Participants

[NEED TO ADD A SUMMARY OF PARTICIPANT INFORMATION: HOW MANY TESTED, DEMOGRAPHIC INFORMATION, HOW WERE PARTICIPANTS REIMBURSED, HOW MANY ASSIGNED TO EACH CONDITION]


## Design

```{r getDifficultySet, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Get all listlength Options options
# 1 = Easy, 2 = Medium, 3 = Hard, 4 = Very hard
difficulty_set = sort(unique(c(cleandata$patch_0, cleandata$patch_1, cleandata$patch_2, cleandata$patch_3)), decreasing = FALSE)

```

[NEED TO ADD A DESCRIPTION OF THE EXPERIMENTAL DESIGN]

_Data Cleaning_

Subjects completed the experiment by clicking a link with the uniquely generated id code. Subjects were able to use the link multiple times; further, subjects were able to exit the experiment at any time. Consequently, the datafile contains partially completed data for some subjects which needed to be identified and removed. 


```{r analyse_RDK_difficulty, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Get typing test data
typing = cleandata %>% filter(trial_event == 'typing_test')


```

```{r set_final_subjects, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}

data = cleandata

# Count remaining subjects
finalSubjects = data %>% distinct(unique_id)
final_n = data %>% distinct(unique_id) %>% count()

```


```{r task_completion, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# tcdata = aggregate(rdk$trial_event[rdk$correct == 1], by=list("condition" = rdk$condition[rdk$correct == 1], "trial" = rdk$trial_number[rdk$correct == 1], "phase" = rdk$phase[rdk$correct == 1], "subject" = rdk$uniqueid[rdk$correct == 1]), FUN=length)

tcdata = typing %>% group_by(trial_number, phase, unique_id) %>% count()
avgCompletions = typing %>% group_by(trial_number, phase, unique_id) %>% count() %>% group_by(phase) %>% summarise(mean = mean(n, na.rm=TRUE))

# Need to run stats to compare number of task completions in each phase
avgSubCompletions = tcdata %>% group_by(unique_id, phase) %>% summarize(mean = mean(n, n.rm=TRUE))
tc.aov = aov(mean ~ phase, data = avgSubCompletions)
summary(tc.aov)

```

# Data Analysis

We first summarize performance by answering the following questions: 

## Task completions

* How many tasks are completed on average?

[ADD ANALYSIS DESCRIPTION]

```{r task_completion_table, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Reorder columns
avgCompletions = avgCompletions[c("phase", "mean")]
kable(avgCompletions, caption="Average number of correctly completed tasks in each condition")
```

[ADD DESCRIPTION OF ANALYSIS OF TASK COMPLETIONS]

## Typing analysis


```{r typing_analysis, echo=FALSE, message=TRUE, warning=FALSE, results="asis"}

# Notes:
# Accuracy data
# data$typed_accuracy[data$trial_event == "typing_test"]

# Typing data
# data$typed_strings[data$trial_event == "typing_test"]

# Typing RT data
# data$typed_times[data$trial_event == "typing_test"]

# WPM
# data$average[data$trial_event == "typing_test"]

# 160422 DL: There was a problem with the experiment recording the typed timing 
# variables. The maximum character length was 255 which was not long enough to 
# capture the typing RTs for the longest lists (because they're recorded 
# system times. Each RT e.g., 1647128182564)

# Convert string arrays into average typing accuracy, average typing rt, and wpm
typingdata = data %>% filter(trial_event == "typing_test")

# Preallocate variables
avgRT = rep(NA, nrow(typingdata))
nRTs = rep(NA, nrow(typingdata))
avgAccuracy = rep(NA, nrow(typingdata))
total_typing_time = rep(NA, nrow(typingdata))

difficulty = as.factor(typingdata$difficulty)
wpm = typingdata$average

for (i in 1:nrow(typingdata)){
  if (!is.na(typingdata$typed_times[i])){
  # Get average typing RTs - Remove brackets and separate by string
  typed_rts = str_split(gsub("[][]", "", typingdata$typed_times[i]), ",") # Remove brackets
  typed_rts = unlist(lapply(typed_rts, as.numeric)) # Convert to numeric array
  
  if (grepl(']', typingdata$typed_times[i])){ # All RTs recorded properly
    rts = typed_rts[2:(length(typed_rts))] - typed_rts[1:(length(typed_rts)-1)]
    avgRT[i] = mean(rts)
    nRTs[i] = length(typed_rts)
  } else { # RTs terminate before final RT recorded (delete last entry)
    rts = typed_rts[2:(length(typed_rts)-1)] - typed_rts[1:(length(typed_rts)-2)]
    avgRT[i] = mean(rts) 
    nRTs[i] = length(typed_rts)-1
  }
  
  
  # Get average typing accuracy
  typed_acc = str_split(gsub("[][]", "", typingdata$typed_accuracy[i]), ",") # Remove brackets
  typed_acc = unlist(lapply(typed_acc, as.numeric)) # Convert to numeric array
  avgAccuracy[i] = mean(typed_acc)
  
  # Approximate total typing time
  total_typing_time[i] = sum(rts) + sum(rep(avgRT[i], length(typed_acc) - length(rts) - 1))
  }
}

subject = typingdata$unique_id
phase = typingdata$phase
trial = typingdata$trial_number


typing_vars = t(as.matrix(rbind(subject, phase, trial, difficulty, avgAccuracy, avgRT, wpm, nRTs, total_typing_time)))
rownames(typing_vars) = NULL
colnames(typing_vars) = c("sub", "phase", "trial", "nWords", "acc", "rt", "wpm", "nRT", "totalTime")
typing_vars = as.data.frame(typing_vars)

typing_vars$phase = as.factor(typing_vars$phase)
levels(typing_vars$phase) = c("untimed", "deadline")


options(digits=2)
typing_analysis = aggregate(list("acc" = typing_vars$acc, "rt" = typing_vars$rt, "wpm" = typing_vars$wpm, "totalTime" = typing_vars$totalTime), by = list("length" = typing_vars$nWords, "phase"=typing_vars$phase), function(x)(round(mean(x, na.rm=TRUE), 2)))

typing_analysis_std = aggregate(list("acc" = typing_vars$acc, "rt" = typing_vars$rt, "wpm" = typing_vars$wpm, "totalTime" = typing_vars$totalTime), by = list("length" = typing_vars$nWords, "phase"=typing_vars$phase), function(x)(round(sd(x, na.rm=TRUE), 2)))
typing_analysis_n = aggregate(list("acc" = typing_vars$acc, "rt" = typing_vars$rt, "wpm" = typing_vars$wpm, "totalTime" = typing_vars$totalTime), by = list("length" = typing_vars$nWords, "phase"=typing_vars$phase), function(x)(length(x)))
typing_analysis_se = typing_analysis_std
typing_analysis_se$acc = typing_analysis_std$acc/sqrt(typing_analysis_n$acc)
typing_analysis_se$rt = typing_analysis_std$rt/sqrt(typing_analysis_n$rt)
typing_analysis_se$wpm = typing_analysis_std$wpm/sqrt(typing_analysis_n$wpm)
typing_analysis_se$totalTime = typing_analysis_std$totalTime/sqrt(typing_analysis_n$totalTime)

kable(typing_analysis, caption="Typing data analysis")
kable(typing_analysis_se, caption="Typing data analysis - standard error")

# [NEED TO ANALYSE THE ACCURACY, RT, AND WPM DATA USING A T-TEST (WITH PHASE AS THE INDEPENDENT VARIABLE)]
sub_typing_vars = aggregate(list("rt" = typing_vars$rt, "acc" = typing_vars$acc, "totalTime" = typing_vars$totalTime, "wpm" = typing_vars$wpm), by = list("sub" = typing_vars$sub, "phase" = typing_vars$phase, "length" = typing_vars$nWords),function(x)(round(mean(x), 2)))

#rt.aov = aov(rt ~ phase + length, data = sub_typing_vars)
rt.aov = anova_test(data = sub_typing_vars, dv = rt, wid = sub, within = c(phase, length))
print(rt.aov)

#acc.aov = aov(acc ~ phase + length, data = sub_typing_vars)
acc.aov = anova_test(data = sub_typing_vars, dv = acc, wid = sub, within = c(phase, length))
print(acc.aov)

#wpm.aov = aov(wpm ~ phase + length, data = sub_typing_vars)
wpm.aov = anova_test(data = sub_typing_vars, dv = wpm, wid = sub, within = c(phase, length))
print(wpm.aov)

#totalTime.aov = aov(totalTime ~ phase + length, data = typing_vars)
totalTime.aov = anova_test(data = sub_typing_vars, dv = totalTime, wid = sub, within = c(phase, length))
print(totalTime.aov)


```


## Reward Rate

[ADD  DESCRIPTION]

```{r rewardRate_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Get reward rate standard error
typing_vars$correct = rep(1, nrow(typing_vars), 1)

rrdata = aggregate(list("accuracy" = typing_vars$correct, "crt" = typing_vars$totalTime), by = list("difficulty" = typing_vars$nWords, "phase" = typing_vars$phase, "subject"=typing_vars$sub), FUN = function(x) mean(x, na.rm = TRUE))

temp = aggregate(list("n" = typing_vars$correct), by = list("difficulty" = typing_vars$nWords, "phase" = typing_vars$phase, "subject"=typing_vars$sub), FUN = function(x) length(x))

rrdata$n = temp$n


# Average score (letter match) values for easy, med, hard, and very hard tasks
# computed from generateWordleClues_matchToTarget.m
rewardscores = c(0.10589, 0.76477, 2.2752, 4.2674)
rrdata$score[rrdata$difficulty == 1] = rewardscores[1]
rrdata$score[rrdata$difficulty == 2] = rewardscores[2]
rrdata$score[rrdata$difficulty == 3] = rewardscores[3]
rrdata$score[rrdata$difficulty == 4] = rewardscores[4]


rrdata$rewardRate = rrdata$score*rrdata$accuracy/(rrdata$crt/1000)

rrdata$difficulty = as.factor(rrdata$difficulty)
levels(rrdata$difficulty) = c("short", "med", "long", "v.long")

subRewardRate = aggregate(list("rr" = rrdata$rewardRate), by = list("difficulty" =  rrdata$difficulty, "phase" = rrdata$phase), FUN = function(x) mean(x, na.rm = TRUE))

subRewardRate.sd = aggregate(list("rr" = rrdata$rewardRate), by = list("difficulty" =  rrdata$difficulty, "phase" = rrdata$phase), FUN = function(x) sd(x, na.rm = TRUE))

counts = aggregate(list("n" = rrdata$n), by = list("difficulty" =  rrdata$difficulty, "phase" = rrdata$phase), FUN = function(x) sum(x, na.rm = TRUE))

subRewardRate$SE = subRewardRate.sd$rr/sqrt(counts$n)

rr_plot <- rrdata %>% ggplot(aes(x=difficulty, y=rewardRate, fill=difficulty)) + geom_violin(adjust = 1.5, trim = TRUE, scale = "width") + geom_jitter(height = 0, width = 0.1) +  stat_summary(fun=mean, geom="point", shape=23, size=2) + facet_wrap(~phase) + labs(y="Reward Rate = Reward*p(Correct)/RT(sec)", x = "Difficulty") + lims(y = c(0, 2))

print(rr_plot + ggtitle("Reward Rate as a function of difficulty"))

anova.rr = anova_test(data = rrdata, dv = rewardRate, wid = subject, within = c(phase, difficulty))
print(anova.rr)

bonfTest = pairwise.t.test(rrdata$rewardRate,  paste(rrdata$difficulty, rrdata$phase), p.adjust.method = "bonf")
print(bonfTest)


```


## Optimality in each condition


* What is the proportion of easy, medium, hard, and very hard tasks selected first, second, third or fourth? 
[ADD DESCRIPTION]

```{r get_selections, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
numberOfTasks = 4 # Number of tasks

all_selection_data = data %>% filter(trial_event %in% c("practice_rdk", "select_rdk"))
selection_data = all_selection_data[!is.na(all_selection_data$selected_difficulty), ] # There are some trials which the selection is NA 

selection_data$trial_event = droplevels(selection_data$trial_event) # drop demographics level

ph = c(rep("untimed", 10), rep("deadline", 30))
cn = c(rep("practice_rdk", 10), rep("select_rdk", 30))
# tr = c(seq(0,9), seq(0,29))
tr = seq(0,39)
sdLength = length(cn) # selection data length for each subject

typing_data = data %>% filter(trial_event %in% c("typing_test"))

selection_data$trial_number[selection_data$trial_event == "select_rdk"] = selection_data$trial_number[selection_data$trial_event == "select_rdk"] + 10


for (i in 1:final_n$n){
    tnum = typing_data$trial_number[typing_data$unique_id == finalSubjects$unique_id[i]]
    tempidx = which(tnum==0) 
    temp = which(tempidx > 5)
    tnum[tempidx[temp[1]]:length(tnum)] = tnum[tempidx[temp[1]]:length(tnum)] + 10
    typing_data$trial_number[typing_data$unique_id == finalSubjects$unique_id[i]] = tnum
    
    for (j in 1:length(tr)){
      if (length(typing_data$difficulty[typing_data$unique_id == finalSubjects$unique_id[i] & typing_data$trial_number == tr[j]]) > 0){
        selection_data$difficulty[selection_data$unique_id == finalSubjects$unique_id[i] & selection_data$trial_number == tr[j]] = typing_data$difficulty[typing_data$unique_id == finalSubjects$unique_id[i] & typing_data$trial_number == tr[j]]
      } else {
        selection_data$difficulty[selection_data$unique_id == finalSubjects$unique_id[i] & selection_data$trial_number == tr[j]] = NA
      }
   }
}
  

# Convert location selections to difficulty order selections
selections = data.frame(subject = rep(finalSubjects$unique_id, each = sdLength), phase = rep(ph, sum(final_n$n)), trial = rep(tr, sum(final_n$n)), selected_difficulty_1 = rep(NA, sum(final_n$n) * sdLength), selected_difficulty_2 = rep(NA, sum(final_n$n) * sdLength), selected_difficulty_3 = rep(NA, sum(final_n$n) * sdLength), selected_difficulty_4 = rep(NA, sum(final_n$n) * sdLength), rt_1 = rep(NA, sum(final_n$n) * sdLength), rt_2 = rep(NA, sum(final_n$n) * sdLength), rt_3 = rep(NA, sum(final_n$n) * sdLength), rt_4 = rep(NA, sum(final_n$n) * sdLength))

selections$phase <- factor(selections$phase, levels = c("untimed", "deadline"))


cnt = 1
total = sum(final_n$n) * sdLength
pb <- txtProgressBar(min = 0, max = total, style = 3)
for (i in 1:sum(final_n$n)){
    for (j in 1:sdLength){
      # Coherence in each location (W, N, E, S) 
      coherence_locations = selection_data %>% filter(unique_id == finalSubjects$unique_id[i], trial_event == cn[j], trial_number == tr[j]) %>% slice(1) %>% select(patch_0, patch_1, patch_2, patch_3)
      
      difficulty_selections = selection_data %>% filter(unique_id == finalSubjects$unique_id[i], trial_event == cn[j], trial_number == tr[j]) %>% pull(difficulty) 

      # coherence_selections = as.numeric(as.vector(coherence_locations)[location_selections[!is.na(location_selections)]])
      # length(coherence_selections) <- numberOfTasks # pad end with NAs
      
      selection_rt = selection_data %>% filter(unique_id == finalSubjects$unique_id[i], trial_event == cn[j], trial_number == tr[j]) %>% pull(rt)
      length(selection_rt) <- numberOfTasks # pad end with NAs
      
      selections$selected_difficulty_1[cnt] = difficulty_selections[1]
      selections$selected_difficulty_2[cnt] = difficulty_selections[2]
      selections$selected_difficulty_3[cnt] = difficulty_selections[3]
      selections$selected_difficulty_4[cnt] = difficulty_selections[4]
      
      selections$rt_1[cnt] = selection_rt[1]
      selections$rt_2[cnt] = selection_rt[2]
      selections$rt_3[cnt] = selection_rt[3]
      selections$rt_4[cnt] = selection_rt[4]

      cnt = cnt + 1
      setTxtProgressBar(pb, cnt)
    }
}
close(pb)

selections$rt_1[selections$rt_1 < 0] = NA
selections$rt_2[selections$rt_2 < 0] = NA
selections$rt_3[selections$rt_3 < 0] = NA
selections$rt_4[selections$rt_4 < 0] = NA

```

```{r find_heatmap, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
fixed_untimed   = selections %>% filter(phase == "untimed") %>% select(selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4) %>% as.matrix()
fixed_deadline  = selections %>% filter( phase == "deadline") %>% select(selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4) %>% as.matrix()


imputeMissingData = function(data, n = numberOfTasks){
  for (i in 1:n){
      data[is.na(data[,i]), i] = mean(data[,i], na.rm=TRUE)
  }
  return(data)
}

fixed_untimed = imputeMissingData(fixed_untimed, numberOfTasks)
fixed_deadline = imputeMissingData(fixed_deadline, numberOfTasks)


fu = fixed_untimed %>% rankagg() %>% destat()
fd = fixed_deadline %>% rankagg() %>% destat()

```

```{r heatmap_plot, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

# Convert to proportions
setUpMat = function(matData){
  mat = t(apply(matData, 1, function(x) x/sum(x)))  
  matMelt = melt(mat)
  names(matMelt) = c("Difficulty", "Order", "value")
  return(matMelt)
}
fumelt = setUpMat(fu$mar)
fdmelt = setUpMat(fd$mar)

hm = rbind(cbind("condition" = rep("Untimed", nrow(fumelt)), fumelt), 
           cbind("condition" = rep("Deadline", nrow(fdmelt)), fdmelt))
hm$condition = factor(hm$condition, levels = c("Untimed", "Deadline"))


hmplot = ggplot(hm, aes(x=Difficulty, y=Order)) +
          geom_tile(aes(fill=value)) +
          scale_fill_gradientn(colours=c("blue","pink", "red")) +
          geom_text(aes(label=round(value, 2))) + 
          scale_y_reverse() +
          facet_wrap(~condition) + 
          labs(y="Selection", x = "Difficulty")
print(hmplot)

```

* Do the marginal distributions differ from uniformity?

We tested whether the marginal distributions were different from uniformly random selection using the fact that the mean rank is distributed according to a  $\chi^2$ distribution with the following test-statistic:
$$\chi^2 = \frac{12N}{k(k+1)}\sum_{j=1}^k \left(m_j - \frac{k+1}{2} \right)^2$$
see (Marden, 1995). 

```{r chi2uniformity, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
selection_n = selections %>% count(phase) 

# Compare heatmaps to uniform
observed <- fu$mean.rank

chi2UniformRank = function(observed, n, k = numberOfTasks){
  ex <- rep((k + 1)/2, k);
  oc <- observed
  
  chi = (12 * n/(k * (k + 1))) * sum((oc - ex)^2) # Test statistic of mean rank under uniformity
  p = dchisq(chi, k-1)
  return(list("chi2" = chi, "chi2p" = p))
}

fu$uni <- chi2UniformRank(fu$mean.rank, selection_n$n[selection_n$phase == "untimed"])
fd$uni <- chi2UniformRank(fd$mean.rank, selection_n$n[selection_n$phase == "deadline"])

chiUniformTable = data.frame("phase" = c("untimed", "deadline"), 
                            "chi2" = round(c(fu$uni$chi2, fd$uni$chi2),2), 
                            "df" = c(3,3),
                            "p" = round(c(fu$uni$chi2p, fd$uni$chi2p), 2))

knitr::kable(chiUniformTable, caption = "Chi2 test of uniformity")

```

[ADD DESCRIPTION]

We compared the location conditions and phases using chi-2 analysis.

```{r chi2btw, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Compare heatmaps to each other
chi2_f_UvsD = chisq.test(cbind(as.vector(fu$mar),as.vector(fd$mar))) # Untimed vs Deadline

chi2compTable = data.frame("Comparison" = c("Untimed vs Deadline"), 
                           "chi2" = round(c(chi2_f_UvsD$statistic), 2),
                           "df" = c(chi2_f_UvsD$parameter),
                           "p"  = round(c(chi2_f_UvsD$p.value), 2))

knitr::kable(chi2compTable, caption = "Pearson's chi-squared test")


# MANOVA-like analysis to compare multiple groups? (Marsden book)

```


```{r distcomp, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Distance parameters
maxdistance = (numberOfTasks * (numberOfTasks-1))/2
missing_penalty = maxdistance/numberOfTasks
allperms = permutations(n=4, r=4, v=1:4, repeats.allowed=FALSE)
nperms = nrow(allperms)

# Compute distance from optimal for all perms
pdist <- rep(NA, nperms)
for (i in 1:nperms){
  distObj = ConDisPairs(table(allperms[i, ], c(4, 3, 2, 1)))
  pdist[i] = distObj$D  
}

# Find average distance based on all partial matches
scorePartialMatches = function(sv, allperms, pdist){
    selVector = as.numeric(sv)
    if (all(is.na(selVector))){ # If no tasks are selected
      # avgd = mean(pdist)
      avgd = NA
    } else {
      if (sum(!is.na(selVector)) > 1){ # If more than one task is selected
        dvec = pdist[apply(t(replicate(nperms, selVector[!is.na(selVector)])) == allperms[, !is.na(selVector)], 1, function(x)all(x))]
      } else { # If only one task is selected
        dvec = pdist[selVector[!is.na(selVector)] == allperms[, !is.na(selVector)]]
      }
      avgd = mean(dvec)
    }
    return(list("avgD" = avgd))
}

# Add average distance column
selections = selections %>% mutate("avgD" = apply(selections %>% select(selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4), 1, function(x)(scorePartialMatches(x, allperms, pdist)$avgD)))


```

```{r dist_analysis, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Compare distributions of distances from optimal
dist_fuVSfd = ks.test(selections %>% filter(phase == "untimed") %>% pull(avgD), selections %>% filter(phase == "deadline") %>% pull(avgD))


ksCompTable = data.frame("Comparison" = c("Untimed vs Deadline"), 
                           "ks" = round(c(dist_fuVSfd$statistic), 2),
                           "p"  = round(c(dist_fuVSfd$p.value), 2))

knitr::kable(ksCompTable, caption = "Kolmolgorov-Smirnoff test")

```


* How optimal were responses? 

```{r plotData, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

avg_plot <- selections %>% ggplot(aes(x=avgD, fill=phase)) + geom_histogram(aes(y=..density..), color="white", alpha=0.6, bins = 6, position="identity") + facet_wrap(~phase) + labs(y="Probability", x = "Avg Distance")
print(avg_plot + ggtitle("Avg Distance from Optimal Order"))

```

## Comparison against Easy to Hard order

```{r distcomp_easyhard, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Distance parameters
#maxdistance = (numberOfTasks * (numberOfTasks-1))/2
#missing_penalty = maxdistance/numberOfTasks
#allperms = permutations(n=4, r=4, v=1:4, repeats.allowed=FALSE)
#nperms = nrow(allperms)

# Compute distance from optimal for all perms
pdist_eh <- rep(NA, nperms)
for (i in 1:nperms){
  distObj_eh = ConDisPairs(table(allperms[i, ], c(1,2, 3, 4)))
  pdist_eh[i] = distObj_eh$D  
}

# Find average distance based on all partial matches
scorePartialMatches_eh = function(sv, allperms, pdist_eh){
    selVector = as.numeric(sv)
    if (all(is.na(selVector))){ # If no tasks are selected
      # avgd_eh = mean(pdist_eh)
      avgd_eh = NA
    } else {
      if (sum(!is.na(selVector)) > 1){ # If more than one task is selected
        dvec = pdist_eh[apply(t(replicate(nperms, selVector[!is.na(selVector)])) == allperms[, !is.na(selVector)], 1, function(x)all(x))]
      } else { # If only one task is selected
        dvec = pdist_eh[selVector[!is.na(selVector)] == allperms[, !is.na(selVector)]]
      }
      avgd_eh = mean(dvec)
    }
    return(list("avgD_eh" = avgd_eh))
}

# Add average distance column
selections = selections %>% mutate("avgD_eh" = apply(selections %>% select(selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4), 1, function(x)(scorePartialMatches_eh(x, allperms, pdist_eh)$avgD_eh)))


```

```{r dist_analysis_eh, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Compare distributions of distances from optimal
dist_fuVSfd_eh = ks.test(selections %>% filter(phase == "untimed") %>% pull(avgD), selections %>% filter(phase == "deadline") %>% pull(avgD))


ksCompTable_eh = data.frame("Comparison" = c("Untimed vs Deadline"), 
                           "ks" = round(c(dist_fuVSfd_eh$statistic), 2),
                           "p"  = round(c(dist_fuVSfd_eh$p.value), 2))

knitr::kable(ksCompTable_eh, caption = "Kolmolgorov-Smirnoff test")

```


* How consistent were responses with an easy to hard ordering? 

```{r plotData_eh, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

avg_plot_eh <- selections %>% ggplot(aes(x=avgD_eh, fill=phase)) + geom_histogram(aes(y=..density..), color="white", alpha=0.6, bins = 6, position="identity") + facet_wrap(~phase) + labs(y="Probability", x = "Avg Distance")
print(avg_plot_eh + ggtitle("Avg Distance from Easy to Hard Order"))

```

## Wordle-Clue Score Analysis 

* How motivated are participants to get the Wordle-Clue guess correct?

Wordle guesses are scored out of 10. A match-in-place is scored 2; a match-out-of-place is scored 1. The final score for each trial is the sum across all letters.

```{r numberWordleTrials, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}

for (i in 1:final_n$n){
  tns = cleandata$trial_number[cleandata$unique_id == finalSubjects$unique_id[i]] # trial numbers for current subjects
  # replace NAs with correct trial number
  for (j in 1:length(tns)){
    cnt = 1; 
    if (is.na(tns[j]) & cnt == 1){
      tns[j] = tns[j-1]  
      cnt = 2;
    }    
    if (is.na(tns[j]) & cnt == 2){
      tns[j] = tns[j-2]  
      cnt = 1;
    }        
  }
  cleandata$trial_number[cleandata$unique_id == finalSubjects$unique_id[i]] = tns # replace the numbers in the data file with the new numbers
}

```

```{r scoreWordleTrials, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
#wordleData = cleandata[cleandata$trial_event == "wordle_clues" | cleandata$trial_event == "wordle_answers", ]
wordleData = cleandata[ cleandata$trial_event == "wordle_answer", ]

#for (i in 1:final_n$n){
#  subwordle = wordleData$score[wordleData$unique_id == finalSubjects$unique_id[i]]
#}

avgWordleScoresBySubject = aggregate(list("score" = wordleData$score), by = list("phase" = wordleData$phase, "subject"= wordleData$unique_id), FUN = function(x) mean(x, na.rm = TRUE))
avgWordleScores = aggregate(list("score" = wordleData$score), by = list("phase" = wordleData$phase), FUN = function(x) mean(x, na.rm = TRUE))

knitr::kable(avgWordleScores, caption = "Average Wordle Scores (Max Score = 10)")

wordle.aov = aov(score ~ phase, data = avgWordleScoresBySubject)
summary(wordle.aov)

```

* What is the correlation between the Wordle-Clue score and the distance from the optimal schedule? From the easy-hard schedule?

This test indicates whether participants who are more motivated to score highly on the wordle test are also more likely to selection optimal schedules. This would be indicated by a significant correlation (high wordle score coupled with a low average distance). We also test the same wordle score compared to the easy-hard schedule. 

```{r correlateWordleWithDistance, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Average selections by phase and subject
corrDataSet = aggregate(list("d" = selections$avgD, "eh_d" = selections$avgD_eh), by = list("phase" = selections$phase, "subject"= selections$subject), FUN = function(x) mean(x, na.rm = TRUE))
corrDataSet$wordleScore = rep(NA, nrow(corrDataSet), 1)


for (i in 1:nrow(corrDataSet)){
    corrDataSet$wordleScore[i] = avgWordleScoresBySubject$score[avgWordleScoresBySubject$phase == corrDataSet$phase[i] & avgWordleScoresBySubject$subject == corrDataSet$subject[i]]
}


# OVERALL
plot(corrDataSet$wordleScore, corrDataSet$d)
cor(corrDataSet$wordleScore, corrDataSet$d)
cor.test(corrDataSet$wordleScore, corrDataSet$d)

# Untimed phase only
plot(corrDataSet$wordleScore[corrDataSet$phase == "untimed"], corrDataSet$d[corrDataSet$phase == "untimed"])
cor(corrDataSet$wordleScore[corrDataSet$phase == "untimed"], corrDataSet$d[corrDataSet$phase == "untimed"])
cor.test(corrDataSet$wordleScore[corrDataSet$phase == "untimed"], corrDataSet$d[corrDataSet$phase == "untimed"])

# Deadline phase only
plot(corrDataSet$wordleScore[corrDataSet$phase == "deadline"], corrDataSet$d[corrDataSet$phase == "deadline"])
cor(corrDataSet$wordleScore[corrDataSet$phase == "deadline"], corrDataSet$d[corrDataSet$phase == "deadline"])
cor.test(corrDataSet$wordleScore[corrDataSet$phase == "deadline"], corrDataSet$d[corrDataSet$phase == "deadline"])

# Overall comparison to easy vs hard order
plot(corrDataSet$wordleScore, corrDataSet$eh_d)
cor(corrDataSet$wordleScore, corrDataSet$eh_d)
cor.test(corrDataSet$wordleScore, corrDataSet$eh_d)

```


```{r detectMissingSelectionData, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Cycle through every trial, from every subject, from each phase, of every condition 
# Determine if the recorded RDK data matches the selection data
conditions = c("words")
phases = c("untimed", "deadline")
max_trials = c(9, 29) # number of trials in the untimed and deadline conditions
# finalSubjects - list of final subject numbers (uniqueIDs)


udata <- data %>% filter(phase == "untimed")
ddata <- data %>% filter(phase == "deadline")


troubleMakers = setNames(data.frame(matrix(ncol = 4, nrow = 0)), c("condition", "unique_id", "phase", "trial_number"))
rcnt= 1;

cnt = 1
total = sum(final_n$n) * 10
pb <- txtProgressBar(min = 0, max = total, style = 3)
# Cycle through untimed data first
for (i in 1:sum(final_n$n)){
  # Extract subject data
  sdata <- udata %>% filter(unique_id == finalSubjects$unique_id[i])
  
  for (j in 0:max_trials[1]){
    # Extract trial data
    tdata <- sdata %>% filter(trial_number == j)
    
    nSelectionEvents = tdata %>% filter(trial_event == "practice_rdk") %>% count()
    nRdkEvents = tdata %>% filter(trial_event == "typing_test") %>% select(difficulty) %>% unique() %>% count()
    
    if (nRdkEvents <= nSelectionEvents){ # do nothing
    } else {
      # Add current subject, condition, phase, and trial to the list of troublesome trials      
      troubleMakers[rcnt, ] = c(tdata$condition[1], tdata$unique_id[1], tdata$phase[1], tdata$trial_number[1])
      rcnt = rcnt + 1
    }
  
  cnt = cnt + 1
  setTxtProgressBar(pb, cnt)
  }
}


cnt = 1
total = sum(final_n$n) * 30
pb <- txtProgressBar(min = 0, max = total, style = 3)
# Cycle through untimed data first
for (i in 1:sum(final_n$n)){
  # Extract subject data
  sdata <- ddata %>% filter(unique_id == finalSubjects$unique_id[i])
  
  for (j in 0:max_trials[2]){
    # Extract trial data
    tdata <- sdata %>% filter(trial_number == j)
    
    nSelectionEvents = tdata %>% filter(trial_event == "select_rdk") %>% count()
    nRdkEvents = tdata %>% filter(trial_event == "typing_test") %>% select(difficulty) %>% unique() %>% count()
    
    if (nRdkEvents <= nSelectionEvents){ # do nothing
    } else {
      # Add current subject, condition, phase, and trial to the list of troublesome trials      
      troubleMakers[rcnt, ] = c(tdata$condition[1], tdata$unique_id[1], tdata$phase[1], tdata$trial_number[1])
      rcnt = rcnt + 1
    }
  
  cnt = cnt + 1
  setTxtProgressBar(pb, cnt)
  }
}

```
