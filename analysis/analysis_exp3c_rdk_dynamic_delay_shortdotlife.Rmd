---
title: "Experiment 3c: Dynamic RDK Direction Judgement, Short Dot Life, 4 Tasks, 500 msec Error Penalty"
author: "knowlabUnimelb"
date: "2021-06-16"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

Ruby Steinberg^1^, Ami Eidels^2^, and Daniel R. Little^1^


^1^ The University of Melbourne, ^2^ The University of Newcastle

```{r load_modules, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
library(tidyverse)
library(workflowr)
#library(Rankcluster)
#library(rankdist) # Crashes rStudio
#library(Kendall)
library(DescTools) # ConDisPairs looks useful
library(gtools) 
library(english)
library(ggplot2)
library(dplyr)
#library(hrbrthemes)
library(knitr)
library(reshape2)
library(png)
library(grid)
library(lme4)
library(lmerTest)
library(rstatix)
library(jpeg)
library(pmr)
library(jmv)
library(betareg)
library(statmod)
```

```{r load_data, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
rm(list=ls())

# Load scheduling analysis functions
#  This file contains functions which are useful across all scheduling experiments
source(paste("analysis", "scheduling_analysis_functions.R", sep="/"))
#source(paste("analysis", "additional_scripts.R", sep="/"))

# Get date and format to YYMMDD
date <- getTodaysDate()

# Set the name of the experiment
experimentName = "dynamic_rdk_shortdotlife" # use the index.Rmd file to track which experiment is which

# Name of the data file containing raw data
datafilename = "2021_exp3c_rdk_data_dynamic_shortdotlife.csv" # Name of data file
inputdir <- "data" # location of raw data
datafn  = paste(inputdir, datafilename,sep="/") # Full data filename

# Read data dictionary to get column names
dataDictionaryfn = "data_dictionary_shortdotlife.csv";
colfile = read.csv(paste(inputdir, dataDictionaryfn, sep="/"), stringsAsFactors = FALSE) # specifies the format of the columns

# Location to save selection file
selectiondir <- "selections"
selectionfn = paste(str_split(datafilename, '.csv', simplify=TRUE)[1], '_selections.csv', sep='');
selectionOutputFile <- paste(inputdir, selectiondir, selectionfn, sep="/")

# Location to save stats analysis files
outputfolder = paste(".", "analysis", "anovaData", sep = '/')  # Output folder

# Read the rawdata
rawdata = read.csv(datafn, header = FALSE, col.names = colfile$Column, colClasses = colfile$Type, stringsAsFactors = FALSE, na.strings='NA') # Add column labels to data

# Remove handful of subjects who partially completed the experiment without an id, 
rawdata = rawdata[!is.na(rawdata$unique_id), ]

# Summary data
loggedSubjects = rawdata %>% distinct(condition, unique_id)
nLoggedSubjects = rawdata %>% distinct(condition, unique_id) %>% count(condition)

```


```{r data_cleaning, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
dataCleaningOutput = cleanRDKdata(rawdata)
cleandata <- dataCleaningOutput$cleandata
subjects <- dataCleaningOutput$subjects
nSubjects <- dataCleaningOutput$nSubjects

# Note:
# phase labels are:
# practice_rdk - selection phase; practice - typing the selected list 
# long_deadline_selection - long deadline phase (x 10); untimed - typing the list
# short_deadline_selection (x 30); deadline - typing the list
```

```{r add_phase_col, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
  cleandata = add_phase_col(cleandata, subjects$unique_id)
  cleandata$phase = as.factor(cleandata$phase)
  levels(cleandata$phase) = c("untimed", "deadline")
```

```{r demographics, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Demographics
demographics = getDemographics(rawdata, nSubjects, subjects)
```

# Method

## Participants

## Design

```{r getCoherenceSet, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Get all coherence options
# .8 = Easy, .5 = Medium, .2 = Hard, .0 = Very hard
coherence_set = sort(unique(c(cleandata$patch_0, cleandata$patch_1, cleandata$patch_2, cleandata$patch_3)), decreasing = TRUE)

```

_Data Cleaning_

Subjects completed the experiment by clicking a link with the uniquely generated id code. Subjects were able to use the link multiple times; further, subjects were able to exit the experiment at any time. Consequently, the datafile contains partially completed data for some subjects which needed to be identified and removed. 

```{r identify_nonlearners, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
rdkoutput = removeRDKnonlearners(cleandata, dot_coherence, FALSE)
data = rdkoutput$data
rdk  = rdkoutput$rdk 
finalSubjects = rdkoutput$finalSubjects 
final_n = rdkoutput$final_n
avgTimeoutPerSubject=rdkoutput$avgTimeoutPerSubject
```


# Data Analysis

We first summarize performance by answering the following questions: 

## Task completions

* How many tasks are completed on average?

```{r task_completion, echo=FALSE, message=FALSE, warning=FALSE, results="hide"}
taskStatsOutput = analyseRDKTaskCompletions(rdk, experimentName, outputfolder, printOutput = FALSE)

avgCompletions = taskStatsOutput$avgCompletions

# Uncomment to see task completion table
# print(taskStatsOutput$table) 

# Uncomment to see stats output
# print(taskStatsOutput$model) 

```

## RDK performance

```{r rdk_anova, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
rdkANOVAoutput = analyseRDKdata(rdk)
rdkANOVAdata = rdkANOVAoutput$anovaData
rdkANOVAaccuracy = rdkANOVAoutput$accuracy
rdkANOVAsummedRT = rdkANOVAoutput$summedRT
```
We next analysed performance on the RDK discriminations. We then asked:

* What was the average completion time and accuracy of the easy, medium, hard, and very hard tasks? 

```{r difficulty_plot, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
makeRDKplots(rdkANOVAdata)
```

We further broke down RTs by condition, deadline, and difficulty. 

```{r conXphaseXdiff, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
diffOutput = computeRewardRate(rdk)
kable(diffOutput$difficulty, digits = 2, caption="Mean accuracy, RT, summed RT, and reward rate attempts for each difficulty and each phase")

rrdata = diffOutput$rrdata

```
## Reward Rate

```{r rewardRate_analysis, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
# Plot reward rate
plotRewardRate(rrdata)

# Reward Rate ANOVA
rrAOV = rewardRateANOVA(rrdata);
rr.aov = rrAOV$anovaData

# Within subjects
kable(rr.aov$rmTable$asDF, digits=3)

# Between subjects
kable(rr.aov$bsTable$asDF, digits=3)
```


## Optimality in each condition


* What is the proportion of easy, medium, hard, and very hard tasks selected first, second, third or fourth? 

```{r get_selections, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
numberOfTasks = 4 # Number of tasks
selections = getRDKselections(data, selectionOutputFile, numberOfTasks, c("practice_rdk", "select_rdk"), FALSE)

```

```{r find_heatmap, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
fu = makeHeatmap(selections, "fixed_moving_shortdotlife"  , "untimed" )
fd = makeHeatmap(selections, "fixed_moving_shortdotlife"  , "deadline" )
ru = makeHeatmap(selections, "random_moving_shortdotlife" , "untimed" )
rd = makeHeatmap(selections, "random_moving_shortdotlife" , "deadline" )
```

```{r heatmap_plot_over_subs, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
  plotHeatmap(fu$avg_rankagg, fd$avg_rankagg, ru$avg_rankagg, rd$avg_rankagg, c('fixed', 'random'))
```

```{r hierarchical_loglinear_model , echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
hmOutput = heatmapStats(selections)

# Uncomment to see output
# summary(hmOutput)
```

* Do the marginal distributions differ from uniformity?

We tested whether the marginal distributions were different from uniformally random selection using the fact that the mean rank is distributed according to a  $\chi^2$ distribution with the following test-statistic:
$$\chi^2 = \frac{12N}{k(k+1)}\sum_{j=1}^k \left(m_j - \frac{k+1}{2} \right)^2$$
see (Marden, 1995). 

```{r chi2uniformity, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
unitable = uniformityTest(selections, c("fixed_moving_shortdotlife", "random_moving_shortdotlife"), c("untimed", "deadline"), fu, fd, ru, rd) 
knitr::kable(unitable, caption = "Chi2 test of uniformity")
```

We compared the location conditions and phases using chi-2 analysis.

* How optimal were responses? 

```{r distanceAnalysis, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Add distances to selections data frame
selections = getDistances(selections)
plotDistances(selections)
distanceAnalysis = distanceStats(selections)
summary(distanceAnalysis)

#ksOutput = analyseDistances(selections, c("fixed_location_shortdotlife", "random_location_shortdotlife"), c("untimed", "deadline"))

# Uncomment to view output
# print(ksOutput)

```

## Stability of selections
```{r entropyAnalysis, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
subEntropy = getSubjectEntropy(selections)
makeSubjectEntropyPlot(subEntropy)
entropyModel = entropyStats(subEntropy)

```

```{r entropyBlockAnalysis, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
blockEntropy = getEntropyOverBlocks(selections)
makeBlockEntropyPlot(blockEntropy)

subBlockEntropy = getSubjectEntropyOverBlocks(selections)
blockEntropyModel = lmer(mean_entropy ~ condition + block + condition:block + (1|subject), subBlockEntropy)
summary(blockEntropyModel)
```

## Selection Choice RTs

```{r first_choice_rt, echo=FALSE, warning=FALSE, message=FALSE, results="asis"}
selection_mean_rts = selections %>% 
  group_by(condition, phase) %>% 
  summarise("mrt_sel1" = mean(rt_1, na.rm=TRUE), "mrt_sel2" = mean(rt_2, na.rm=TRUE), "mrt_sel3" = mean(rt_3, na.rm=TRUE), "mrt_sel4" = mean(rt_4, na.rm=TRUE)) 

kable(selection_mean_rts, caption = "Mean RTs for each scheduling selection", digits = 2)

rtAOV = selectionRTstats(selections)
print(rtAOV)
```

# Selection model

We can treat each task selection as a probabilistic choice given by a Luce's choice rule (Luce, 1959), where each task is represented by some strength, $\nu$. The probability of selecting task $i_j$ from set $S = \{i_1, i_2, ..., i_J \}$, where J is the number of tasks, is:

$$p\left(i_j |S \right) = \frac{\nu_{i_j}}{\sum_{i \in S} \nu_{i}}. $$

Plackett (1975) generalised this model to explain the distribution over a sequence of choices (i.e., ranks). In this case, after each choice, the choice set is reduce by one (i.e., sampling without replacement). This probability of observing a specific selection order, $i_1 \succ ... \succ i_J$ is:

$$p\left(i_j |A \right) = \prod_{j=1}^J \frac{\nu_{i_j}}{\sum_{i \in A_j} \nu_{i}}, $$

where $A_j$ is the current choice set.


```{r PLmodel_bySubject, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
fu = selections %>% 
  filter(condition == "fixed_moving_shortdotlife", phase == "untimed") %>% 
  select(subject, trial, selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4) %>%
  as.matrix() %>% 
  getPLparametersBySubject()

fd = selections %>% 
  filter(condition == "fixed_moving_shortdotlife", phase == "deadline") %>% 
  select(subject, trial, selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4) %>%
  as.matrix() %>% 
  getPLparametersBySubject()

ru = selections %>% 
  filter(condition == "random_moving_shortdotlife", phase == "untimed") %>% 
  select(subject, trial, selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4) %>%
  as.matrix() %>% 
  getPLparametersBySubject()

rd = selections %>% 
  filter(condition == "random_moving_shortdotlife", phase == "deadline") %>% 
  select(subject, trial, selected_difficulty_1, selected_difficulty_2, selected_difficulty_3, selected_difficulty_4) %>%
  as.matrix() %>% 
  getPLparametersBySubject()
```


```{r PLmodel_table, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
slopemeans = c(mean(fu$plSlopes), mean(fd$plSlopes), mean(ru$plSlopes), mean(rd$plSlopes))
slopeses = c(sd(fu$plSlopes)/sqrt(length(fu$plSlopes)), sd(fd$plSlopes)/sqrt(length(fd$plSlopes)), 
             sd(ru$plSlopes)/sqrt(length(ru$plSlopes)), sd(rd$plSlopes)/sqrt(length(rd$plSlopes)))

plTable = data.frame("condition" = c("fixed", "fixed", "random", "random"),
                     "phase" = c("untimed", "deadline", "untimed", "deadline"),
                     "pl.easy"     = c(fu$mean_pl[1], fd$mean_pl[1], ru$mean_pl[1], rd$mean_pl[1]),
                     "pl.easy.se"  = c(fu$se_pl[1]  , fd$se_pl[1],   ru$se_pl[1],   rd$se_pl[1]),
                     "pl.med"      = c(fu$mean_pl[2], fd$mean_pl[2], ru$mean_pl[2], rd$mean_pl[2]),
                     "pl.med.se"   = c(fu$se_pl[2]  , fd$se_pl[2],   ru$se_pl[2],   rd$se_pl[2]),
                     "pl.hard"     = c(fu$mean_pl[3], fd$mean_pl[3], ru$mean_pl[3], rd$mean_pl[3]),
                     "pl.hard.se"  = c(fu$se_pl[3]  , fd$se_pl[3],   ru$se_pl[3],   rd$se_pl[3]),
                     "pl.vhard"    = c(fu$mean_pl[4], fd$mean_pl[4], ru$mean_pl[4], rd$mean_pl[4]),
                     "pl.vhard.se" = c(fu$se_pl[4]  , fd$se_pl[4],   ru$se_pl[4],   rd$se_pl[4]),
                     "slope"       = slopemeans,
                     "slope.se"    = slopeses)
                    
knitr::kable(plTable, caption = "Mean strength estimates (and standard errors) for Plackett-Luce model", digits=2)


```

```{r PLslope_ANOVA, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Combine arrays into a data frame with labels
pldata <- data.frame(
  value = c(fu$plSlopes, fd$plSlopes, ru$plSlopes, rd$plSlopes),
  condition = rep(c("fixed", "fixed", "random", "random"), 
                  times = c(length(fu$plSlopes), length(fd$plSlopes), length(ru$plSlopes), length(rd$plSlopes))),
  phase = rep(c("untimed", "deadline", "untimed", "deadline"), 
              times = c(length(fu$plSlopes), length(fd$plSlopes), length(ru$plSlopes), length(rd$plSlopes)))
)

anova_result <- aov(value ~ condition * phase, data = pldata)

# Print the summary of the ANOVA
summary(anova_result)

```

```{r notes, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
#files_to_build <- list.files("analysis", pattern = "^analysis_exp3c_.*\\.Rmd$", full.names = TRUE)
#wflow_build(files = files_to_build)
#wflow_publish(files_to_build, message = "Update analysis code to use shared file repo")
#wflow_git_push() - returns an error: Error: Push failed for unknown reason.
#  Try opening a terminal, navigate to C:\Users\littled\Dropbox\Work\SCHEDULING
#  git push -u origin master
```


```{r detectMissingSelectionData, echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# # Cycle through every trial, from every subject, from each phase, of every condition 
# # Determine if the recorded RDK data matches the selection data
# conditions = c("fixed", "random")
# phases = c("untimed", "deadline")
# max_trials = c(9, 29) # number of trials in the untimed and deadline conditions
# # finalSubjects - list of final subject numbers (unique_ids)
# 
# 
# udata <- data %>% filter(phase == "untimed")
# ddata <- data %>% filter(phase == "deadline")
# 
# 
# troubleMakers = setNames(data.frame(matrix(ncol = 4, nrow = 0)), c("condition", "unique_id", "phase", "trial_number"))
# rcnt= 1;
# 
# cnt = 1
# total = sum(final_n$n) * 10
# pb <- txtProgressBar(min = 0, max = total, style = 3)
# # Cycle through untimed data first
# for (i in 1:sum(final_n$n)){
#   # Extract subject data
#   sdata <- udata %>% filter(unique_id == finalSubjects$unique_id[i])
#   
#   for (j in 0:max_trials[1]){
#     # Extract trial data
#     tdata <- sdata %>% filter(trial_number == j)
#     
#     nSelectionEvents = tdata %>% filter(trial_event == "practice_rdk") %>% count()
#     nRdkEvents = tdata %>% filter(trial_event == "rdk") %>% select(dot_coherence) %>% unique() %>% count()
#     
#     if (nRdkEvents <= nSelectionEvents){ # do nothing
#     } else {
#       # Add current subject, condition, phase, and trial to the list of troublesome trials      
#       troubleMakers[rcnt, ] = c(tdata$condition[1], tdata$unique_id[1], tdata$phase[1], tdata$trial_number[1])
#       rcnt = rcnt + 1
#     }
#   
#   cnt = cnt + 1
#   setTxtProgressBar(pb, cnt)
#   }
# }
# 
# 
# cnt = 1
# total = sum(final_n$n) * 30
# pb <- txtProgressBar(min = 0, max = total, style = 3)
# # Cycle through untimed data first
# for (i in 1:sum(final_n$n)){
#   # Extract subject data
#   sdata <- ddata %>% filter(unique_id == finalSubjects$unique_id[i])
#   
#   for (j in 0:max_trials[2]){
#     # Extract trial data
#     tdata <- sdata %>% filter(trial_number == j)
#     
#     nSelectionEvents = tdata %>% filter(trial_event == "select_rdk") %>% count()
#     nRdkEvents = tdata %>% filter(trial_event == "rdk") %>% select(dot_coherence) %>% unique() %>% count()
#     
#     if (nRdkEvents <= nSelectionEvents){ # do nothing
#     } else {
#       # Add current subject, condition, phase, and trial to the list of troublesome trials      
#       troubleMakers[rcnt, ] = c(tdata$condition[1], tdata$unique_id[1], tdata$phase[1], tdata$trial_number[1])
#       rcnt = rcnt + 1
#     }
#   
#   cnt = cnt + 1
#   setTxtProgressBar(pb, cnt)
#   }
# }

```
