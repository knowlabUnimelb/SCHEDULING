<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="knowlabUnimelb" />

<meta name="date" content="2020-10-29" />

<title>Experiment 1: RDK Direction Judgement, 4 Tasks, No Error Penalty</title>

<script src="site_libs/header-attrs-2.13/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">SCHEDULING</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Experiment 1: RDK Direction Judgement, 4
Tasks, No Error Penalty</h1>
<h4 class="author">knowlabUnimelb</h4>
<h4 class="date">2020-10-29</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2022-11-09
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>SCHEDULING/</code> <span
class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.0). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20221107code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20221107)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20221107code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20221107)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrong67e1aac">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong> 67e1aac
</a>
</p>
</div>
<div id="strongRepositoryversionstrong67e1aac"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version 67e1aac.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rproj.user/
    Ignored:    analysis/patch_selection.png
    Ignored:    analysis/patch_selection_8.png
    Ignored:    analysis/patch_selection_avg.png
    Ignored:    analysis/site_libs/

Untracked files:
    Untracked:  analysis/Notes.txt
    Untracked:  analysis/archive/
    Untracked:  analysis/fd_pl.rds
    Untracked:  analysis/fu_pl.rds
    Untracked:  analysis/prereg/
    Untracked:  analysis/reward rate analysis.docx
    Untracked:  analysis/rewardRate.jpg
    Untracked:  analysis/toAnalyse/
    Untracked:  analysis/wflow_code_string.txt
    Untracked:  archive/
    Untracked:  data/archive/
    Untracked:  data/create_database.sql
    Untracked:  data/dataToAnalyse/
    Untracked:  data/exp6a_typing_exponential.xlsx
    Untracked:  data/exp6b_typing_linear.xlsx
    Untracked:  data/rawdata_incEmails/
    Untracked:  data/sona data/
    Untracked:  data/summaryFiles/
    Untracked:  models/
    Untracked:  old Notes on analysis.txt
    Untracked:  presentations/
    Untracked:  references/
    Untracked:  spatial_pdist.Rdata

Unstaged changes:
    Modified:   data/README.md

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown
(<code>analysis/analysis_exp1_labelled_nodelay.Rmd</code>) and HTML
(<code>docs/analysis_exp1_labelled_nodelay.html</code>) files. If you’ve
configured a remote Git repository (see <code>?wflow_git_remote</code>),
click on the hyperlinks in the table below to view the files as they
were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
67e1aac
</td>
<td>
knowlabUnimelb
</td>
<td>
2022-11-09
</td>
<td>
Publish data and analysis files
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<p>Daniel R. Little<sup>1</sup>, Ami Eidels<sup>2</sup>, and Deborah J.
Lin<sup>1</sup></p>
<p><sup>1</sup> The University of Melbourne, <sup>2</sup> The University
of Newcastle</p>
<div id="method" class="section level1">
<h1>Method</h1>
<div id="participants" class="section level2">
<h2>Participants</h2>
<p>We tested 97 participants (62 F, 28 M, 7 Undeclared). Participants
were recruited through the Melbourne School of Psychological Sciences
Research Experience Pool (Mean age = 19.48, range = 17 - 49).
Participants were reimbursed with credit toward completion of a
first-year psychology subject. Datasets from 3 subjects were excluded
for completing the experiment more than once; i.e., only the first of
the datasets for these subjects was retained.</p>
<p>Forty-nine were assigned to the <em>Fixed Difficulty</em> condition.
In this condition, the location of easy, medium, hard, and very hard
random dot kinematograms (RDK’s) was held constant across trials.</p>
<p>Forty-eight were assigned to the <em>Random Difficulty</em>
condition. In this condition, the location of easy, medium, hard, and
very hard random dot kinematograms (RDK’s) were randomized from trial to
trial.</p>
<p>The Fixed Difficulty experiment was completed before the Random
Difficulty experiment. Participants only completed one of these.</p>
</div>
<div id="design" class="section level2">
<h2>Design</h2>
<p>In each condition, participants completed multiple trials in which
they selected and completed RDK tasks. On each trial, participants were
shown a set of four RDKs labelled “Easy”, “Medium”, “Hard”, and “Very
Hard”. The labels corresponded to the coherence of the RDK; that is, the
proportion of dots moving in a coherent direction, which was set to 80%,
50%, 20%, and 0% for the Easy, Medium, Hard, and Very Hard locations,
respectively. From the set of four RDKs, participants selected and
completed one RDK at a time in any order. The goal of each trial was to
complete as many as possible before a deadline. If an incorrect RDK
response was made, that RDK was restarted at the same coherence but with
a new randomly sampled direction, and the participant had to respond to
the RDK again. A new task could not be selected until the RDK was
completed successfully.</p>
<p><img src="figure/analysis_exp1_labelled_nodelay.Rmd/taskImage-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Participants first completed 10 trials with a long (30 sec) deadline
to help participants learn the task, explore strategies, and allow for
comparison to a short-deadline condition. We term this the <em>no
deadline</em> condition since the provided time is well beyond what is
necessary to complete all four RDK’s. Next, participants completed 30
trials with a 6 second deadline.</p>
<p><em>Data Cleaning</em></p>
<p>Subjects completed the experiment by clicking a link with the
uniquely generated id code. Subjects were able to use the link multiple
times; further, subjects were able to exit the experiment at any time.
Consequently, the datafile contains partially completed data for some
subjects which needed to be identified and removed.</p>
<p>A handful of subjects (N = 15) had less than chance accuracy on the
easiest RDK indicating equipment problems or a misunderstanding of task
directions. We removed these participants from further anlaysis leaving
42 and 40 in the fixed and random location conditions, respectively.</p>
</div>
</div>
<div id="data-analysis" class="section level1">
<h1>Data Analysis</h1>
<p>We first summarize performance by answering the following
questions:</p>
<div id="task-completions" class="section level2">
<h2>Task completions</h2>
<ul>
<li>How many tasks are completed on average?</li>
</ul>
<p>Across both conditions, participants completed 3.9 tasks during the
phase and NaN tasks during the phase.</p>
<table>
<caption>Average number of correctly completed tasks in each
condition</caption>
<thead>
<tr class="header">
<th align="left">condition</th>
<th align="left">phase</th>
<th align="right">mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">untimed</td>
<td align="right">3.907090</td>
</tr>
<tr class="even">
<td align="left">fixed</td>
<td align="left">deadline</td>
<td align="right">3.388294</td>
</tr>
<tr class="odd">
<td align="left">random</td>
<td align="left">untimed</td>
<td align="right">3.887500</td>
</tr>
<tr class="even">
<td align="left">random</td>
<td align="left">deadline</td>
<td align="right">3.270067</td>
</tr>
</tbody>
</table>
<p>As one might expect, there were fewer tasks completed under a
deadline than without a deadline (<span
class="math inline">\(\beta_{deadline}\)</span> = 0.54, SE = 0.07).<a
href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> There was
no difference between conditions, (<span
class="math inline">\(\beta_{condition}\)</span> = 0.02, SE = 0.05), and
no interaction between deadline and location condition (<span
class="math inline">\(\beta_{condition \times deadline}\)</span>= 0.08,
SE = 0.11). <a href="#fn2" class="footnote-ref"
id="fnref2"><sup>2</sup></a></p>
</div>
<div id="rdk-performance" class="section level2">
<h2>RDK performance</h2>
<p>We next analysed performance on the RDK discriminations. We then
asked:</p>
<ul>
<li>What was the average completion time and accuracy of the easy,
medium, hard, and very hard tasks?</li>
</ul>
<p>RTs became shorter and more accurate as the difficulty of the RDK
became easier. As expected, the RTs were shorter under a deadline than
without a deadline. We visualised the response times in two ways: First,
we simply took the average of each attempt on each RDK.</p>
<!-- after first removing 438 trials which had RTs greater than 3000 msec.  -->
<p><img src="figure/analysis_exp1_labelled_nodelay.Rmd/difficulty_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Second, we computed the time to complete an RDK as the cumulative sum
across multiple attempts within a trial (termed Cumulative RT or cRT).
That is, if an error is made and the RDK needs to be repeated, then the
total RT is the sum of both attempts.</p>
<p><img src="figure/analysis_exp1_labelled_nodelay.Rmd/difficulty_sum_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>We further broke down RTs by condition, deadline, and difficulty.</p>
<table>
<caption>Mean accuracy, RT, and RT summed across attempts for each
difficulty and each phase</caption>
<colgroup>
<col width="11%" />
<col width="10%" />
<col width="12%" />
<col width="5%" />
<col width="14%" />
<col width="12%" />
<col width="8%" />
<col width="6%" />
<col width="10%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">condition</th>
<th align="left">phase</th>
<th align="left">difficulty</th>
<th align="right">n</th>
<th align="right">Mean.Correct</th>
<th align="right">SE.Correct</th>
<th align="right">Mean.RT</th>
<th align="right">SE.RT</th>
<th align="right">Mean.crt</th>
<th align="right">SE.crt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">untimed</td>
<td align="left">easy</td>
<td align="right">712</td>
<td align="right">0.88</td>
<td align="right">0.01</td>
<td align="right">1108.01</td>
<td align="right">51.42</td>
<td align="right">1253.37</td>
<td align="right">65.31</td>
</tr>
<tr class="even">
<td align="left">fixed</td>
<td align="left">untimed</td>
<td align="left">medium</td>
<td align="right">528</td>
<td align="right">0.88</td>
<td align="right">0.01</td>
<td align="right">1112.20</td>
<td align="right">45.10</td>
<td align="right">1266.36</td>
<td align="right">54.53</td>
</tr>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">untimed</td>
<td align="left">hard</td>
<td align="right">460</td>
<td align="right">0.76</td>
<td align="right">0.02</td>
<td align="right">1390.44</td>
<td align="right">56.22</td>
<td align="right">1821.72</td>
<td align="right">86.57</td>
</tr>
<tr class="even">
<td align="left">fixed</td>
<td align="left">untimed</td>
<td align="left">v. hard</td>
<td align="right">457</td>
<td align="right">0.55</td>
<td align="right">0.02</td>
<td align="right">1849.33</td>
<td align="right">68.70</td>
<td align="right">3333.47</td>
<td align="right">165.28</td>
</tr>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">deadline</td>
<td align="left">easy</td>
<td align="right">1281</td>
<td align="right">0.89</td>
<td align="right">0.01</td>
<td align="right">518.26</td>
<td align="right">5.76</td>
<td align="right">581.46</td>
<td align="right">8.82</td>
</tr>
<tr class="even">
<td align="left">fixed</td>
<td align="left">deadline</td>
<td align="left">medium</td>
<td align="right">1356</td>
<td align="right">0.86</td>
<td align="right">0.01</td>
<td align="right">549.75</td>
<td align="right">6.73</td>
<td align="right">629.84</td>
<td align="right">11.92</td>
</tr>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">deadline</td>
<td align="left">hard</td>
<td align="right">1329</td>
<td align="right">0.76</td>
<td align="right">0.01</td>
<td align="right">601.29</td>
<td align="right">7.92</td>
<td align="right">754.96</td>
<td align="right">13.93</td>
</tr>
<tr class="even">
<td align="left">fixed</td>
<td align="left">deadline</td>
<td align="left">v. hard</td>
<td align="right">1288</td>
<td align="right">0.62</td>
<td align="right">0.01</td>
<td align="right">598.48</td>
<td align="right">9.31</td>
<td align="right">846.19</td>
<td align="right">16.89</td>
</tr>
<tr class="odd">
<td align="left">random</td>
<td align="left">untimed</td>
<td align="left">easy</td>
<td align="right">741</td>
<td align="right">0.88</td>
<td align="right">0.01</td>
<td align="right">1084.88</td>
<td align="right">39.76</td>
<td align="right">1230.81</td>
<td align="right">56.18</td>
</tr>
<tr class="even">
<td align="left">random</td>
<td align="left">untimed</td>
<td align="left">medium</td>
<td align="right">557</td>
<td align="right">0.79</td>
<td align="right">0.02</td>
<td align="right">1023.30</td>
<td align="right">41.28</td>
<td align="right">1283.68</td>
<td align="right">56.52</td>
</tr>
<tr class="odd">
<td align="left">random</td>
<td align="left">untimed</td>
<td align="left">hard</td>
<td align="right">493</td>
<td align="right">0.70</td>
<td align="right">0.02</td>
<td align="right">1353.25</td>
<td align="right">56.33</td>
<td align="right">1937.68</td>
<td align="right">90.44</td>
</tr>
<tr class="even">
<td align="left">random</td>
<td align="left">untimed</td>
<td align="left">v. hard</td>
<td align="right">447</td>
<td align="right">0.52</td>
<td align="right">0.02</td>
<td align="right">1534.86</td>
<td align="right">62.46</td>
<td align="right">2946.45</td>
<td align="right">140.13</td>
</tr>
<tr class="odd">
<td align="left">random</td>
<td align="left">deadline</td>
<td align="left">easy</td>
<td align="right">1444</td>
<td align="right">0.82</td>
<td align="right">0.01</td>
<td align="right">468.98</td>
<td align="right">6.09</td>
<td align="right">567.78</td>
<td align="right">8.33</td>
</tr>
<tr class="even">
<td align="left">random</td>
<td align="left">deadline</td>
<td align="left">medium</td>
<td align="right">1413</td>
<td align="right">0.79</td>
<td align="right">0.01</td>
<td align="right">489.26</td>
<td align="right">6.45</td>
<td align="right">608.70</td>
<td align="right">10.53</td>
</tr>
<tr class="odd">
<td align="left">random</td>
<td align="left">deadline</td>
<td align="left">hard</td>
<td align="right">1320</td>
<td align="right">0.66</td>
<td align="right">0.01</td>
<td align="right">504.61</td>
<td align="right">7.60</td>
<td align="right">708.76</td>
<td align="right">14.69</td>
</tr>
<tr class="even">
<td align="left">random</td>
<td align="left">deadline</td>
<td align="left">v. hard</td>
<td align="right">1339</td>
<td align="right">0.58</td>
<td align="right">0.01</td>
<td align="right">527.30</td>
<td align="right">8.76</td>
<td align="right">823.15</td>
<td align="right">18.90</td>
</tr>
</tbody>
</table>
<p>Statistical analysis, using a 2 condition <span
class="math inline">\(\times\)</span> 2 phase <span
class="math inline">\(\times\)</span> 4 difficulty between-within ANOVA,
of the effect of these factors on accuracy confirmed the effect of
difficulty, F(3, 231) = 173.57, p = 0, <span
class="math inline">\(\eta^2\)</span> = 0.4. RDK responses in the fixed
condition were more accurate than RDK responses in the random condition,
F(1, 77) = 7.19, p = 0.01, <span class="math inline">\(\eta^2\)</span> =
0.03. RDK responses were not more accurate under a deadline then under
no deadline, F(1, 77) = 2.21, p = 0.14, <span
class="math inline">\(\eta^2\)</span> = 0. However, there was a
significant phase <span class="math inline">\(\times\)</span> difficulty
interaction, F(3, 231) = 3.48, p = 0.02, <span
class="math inline">\(\eta^2\)</span> = 0.01 reflecting a greater
increase from easy to very hard when there was no deadline compared to
when there was a deadline.</p>
<p>We used the same analysis to examine the effect of condition, phase,
and difficulty on RT. We confirmed that RTs were shorter under a
deadline, F(1, 77) = 180.2, p = 0, <span
class="math inline">\(\eta^2\)</span> = 0.39, and that RTs became
shorter as the RDK’s became easier, F(3, 231) = 39.14, p = 0, <span
class="math inline">\(\eta^2\)</span> = 0.07. There was again an
interaction between phase and difficulty, F(3, 231) = 38.74, p = 0,
<span class="math inline">\(\eta^2\)</span> = 0.05 indicating that RT
decreased more with increasing dot coherence when there was no deadline
compared to when there was a deadline. These results accord with the
vast literature on RDK performance (see e.g., Ludwig &amp; Evens,
2017).</p>
<p>Finally, we repeated the analysis using the cRT examining the effect
of condition, phase, and difficulty. We confirmed that cRTs were shorter
under a deadline, F(1, 77) = 190.78, p = 0, <span
class="math inline">\(\eta^2\)</span> = 0.35, and that RTs became
shorter as the RDK’s became easier, F(3, 231) = 86.94, p = 0, <span
class="math inline">\(\eta^2\)</span> = 0.22. There was again an
interaction between phase and difficulty, F(3, 231) = 64.63, p = 0,
<span class="math inline">\(\eta^2\)</span> = 0.15 indicating that RT
decreased more with increasing dot coherence when there was no deadline
compared to when there was a deadline.</p>
</div>
<div id="reward-rate" class="section level2">
<h2>Reward Rate</h2>
<p>To confirm that coherence offered a good proxy for difficulty (and
hence, that an optimal order of easiest to hardest was maintained), we
calculated the reward rate for each patch. Reward rate can be defined as
“the proportion of correct trials divided by the average duration
between decisions” (Gold &amp; Shadlen, 2002), and is tantamount, in our
task, to percentage of correct responses per unit time (Bogacz et al,
2006). For our purposes, we can fix time at 1 sec calculate the Reward
Rate as the number of RDK tasks completed in 1 sec.</p>
<p>By assumption, the weight of all tasks is the same and is equal to,
say, 1 point each. Normally, we would expect performance on easier tasks
to be both faster and more accurate. The optimal strategy to complete as
many tasks as possible (thereby maximising reward rate) should then be
to approach them by order of difficulty, easy to hardest. But what if,
for example, on hard tasks, people guess quickly? They could gain points
and waste very little time, possibly leading to a sizable reward
rate.</p>
<p>Take the following hypothetical example: suppose you complete an easy
task with perfect accuracy but take a long time to make the perceptual
decision, say MRT = 2 sec. Suppose then the very difficult condition is
too hard to judge. It would take &gt; 2 secs to judge correct, but you
can and guess quickly and average a time less than 2 sec, say MRT = 0.5
sec. With two response alternatives your odds are 50% so over the long
run you are better off starting with the hardest task, with chance
accuracy and no time lost (of course, one may also guess on the easy
task, and we can check the data to see if people do so). The next
section calculates reward rate for each of the four difficulty
conditions, based on empirical data delineating % correct and MRT.</p>
<p>Inspection of the figure reveals that RR is roughly monotonically
increasing when tasks become easier. Under such conditions, the optimal
order of task-completion should be easy-to-hardest. This could change in
a predictable manner if people value differently easy and hard tasks
(overweight completion of harder tasks). The only notable exception was
in the fixed, no deadline task, where the easy and medium RDK conditions
had equal RR.</p>
<p><img src="figure/analysis_exp1_labelled_nodelay.Rmd/rewardRate_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="optimality-in-each-condition" class="section level2">
<h2>Optimality in each condition</h2>
<p>Having now established that the RDK’s are ordered in accuracy,
difficulty, and reward rate, it is clear that the task set presented to
each subject has an optimal solution, ordered from easiest to most
difficult. We now ask:</p>
<ul>
<li>What is the proportion of easy, medium, hard, and very hard tasks
selected first, second, third or fourth?</li>
</ul>
<p>We first compute the marginal distribution of the ranks of each of
the tasks; in other words, what are the proportions of the ranks of each
task in each rank position. These matrices indicate the proportions of
responses for each difficulty level which were chosen first, second,
third, or fourth, respectively. The matrix from a dataset in which
choice is always optimal would have ones on the diagonal and zeros on
the off-diagonal.</p>
<p><img src="figure/analysis_exp1_labelled_nodelay.Rmd/heatmap_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<ul>
<li>Do the marginal distributions differ from uniformity?</li>
</ul>
<p>We tested whether the marginal distributions were different from
uniformally random selection using the fact that the mean rank is
distributed according to a <span class="math inline">\(\chi^2\)</span>
distribution with the following test-statistic: <span
class="math display">\[\chi^2 = \frac{12N}{k(k+1)}\sum_{j=1}^k \left(m_j
- \frac{k+1}{2} \right)^2\]</span> see (Marden, 1995).</p>
<table>
<caption>Chi2 test of uniformity</caption>
<thead>
<tr class="header">
<th align="left">condition</th>
<th align="left">phase</th>
<th align="right">chi2</th>
<th align="right">df</th>
<th align="right">p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">untimed</td>
<td align="right">375.71</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">fixed</td>
<td align="left">deadline</td>
<td align="right">2358.85</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">random</td>
<td align="left">untimed</td>
<td align="right">161.89</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">random</td>
<td align="left">deadline</td>
<td align="right">197.34</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>It is evident at a glance that the ordering of choices is more
optimal when the locations are fixed; that is, the proportions on the
diagonal are higher. When the locations are fixed, choice order becomes
more optimal under a deadline. By contrast, when locations are random,
responding becomes <em>less</em> optimal under a deadline. This likely
reflects the additional costs of having to search for the appropriate
task to complete. This search is minimised in the fixed location
condition.</p>
<p>We compared the location conditions and phases using chi-2
analysis.</p>
<table>
<caption>Pearson’s chi-squared test</caption>
<thead>
<tr class="header">
<th align="left">Comparison</th>
<th align="right">chi2</th>
<th align="right">df</th>
<th align="right">p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Fixed: Untimed vs Deadline</td>
<td align="right">270.98</td>
<td align="right">15</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Random: Untimed vs Deadline</td>
<td align="right">92.70</td>
<td align="right">15</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">Untimed: Fixed vs Random</td>
<td align="right">73.61</td>
<td align="right">15</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Deadline: Fixed vs Random</td>
<td align="right">1604.07</td>
<td align="right">15</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<!-- * We next ask whether the sequence of choices reflected the optimal order: What is the proportion of easy-task-first choices in each condition? Of easy-then-medium? Of easy-medium-then-hard? This provides an indication of how the order of responding deviates from optimal in each condition. The table presents the proportion of subjects responding with each order; the figure presents the frequency with which subjects respond with the easiest first RDK, easiest then medium, and so on. -->
<ul>
<li>How optimal were responses?</li>
</ul>
<p>The next analysis computed the distance between the selected order
and the optimal order (easiest to very hard for that trial), which
ranges between 0 (perfect match) and 6 (maximally distant), for 4
options.</p>
<p>What we want is the distance of the selected options from the optimal
solutions, which is the edit distance (or number of discordant pairs)
between orders. However, because a participant may run out of time,
there may be missing values. To handle these values, for each trial, we
find the orders which partially match the selected order and compute
three the average distance of those possible orders and the optimal
solution (<em>avg_distance</em>).</p>
<p>The following figure compares the avg_distance between the fixed
difficulty and random difficulty conditions as a function of deadline
condition and phase. For each of these measures, lower values reflect
respones which are closer to optimal.</p>
</div>
</div>
<div id="selection-model" class="section level1">
<h1>Selection model</h1>
<p>We can treat each task selection as a probabilistic choice given by a
Luce’s choice rule (Luce, 1959), where each task is represented by some
strength, <span class="math inline">\(\nu\)</span>. The probability of
selecting task <span class="math inline">\(i_j\)</span> from set <span
class="math inline">\(S = \{i_1, i_2, ..., i_J \}\)</span>, where J is
the number of tasks, is:</p>
<p><span class="math display">\[p\left(i_j |S \right) =
\frac{\nu_{i_j}}{\sum_{i \in S} \nu_{i}}. \]</span></p>
<p>Plackett (1975) generalised this model to explain the distribution
over a sequence of choices (i.e., ranks). In this case, after each
choice, the choice set is reduce by one (i.e., sampling without
replacement). This probability of observing a specific selection order,
<span class="math inline">\(i_1 \succ ... \succ i_J\)</span> is:</p>
<p><span class="math display">\[p\left(i_j |A \right) = \prod_{j=1}^J
\frac{\nu_{i_j}}{\sum_{i \in A_j} \nu_{i}}, \]</span></p>
<p>where <span class="math inline">\(A_j\)</span> is the current choice
set.</p>
<p><img src="figure/analysis_exp1_labelled_nodelay.Rmd/PLmodel-1.png" width="672" style="display: block; margin: auto;" /></p>
<div id="sampling-distribution-anlaysis" class="section level2">
<h2>Sampling distribution anlaysis</h2>
<p>In order to characterise performance, we examined three sampling
distributions for comparison to our data. The first is the sampling
distribution of edit distances from optimal assuming that orders are
sampled uniformly at random. The second distribution assumes that the
first choice was optimal but the remaining orders are sampled at random.
Finally, the third distributions assumes that the first two choices are
selected optimally but that the remaining are randomly selected. It is
clear that the mode of the distribution moves from a distance of 3 to a
distance of 0 as the sampling distribution summarises orders which
better conform to optimality.</p>
<p>To characterise the optimality of each condition at each point in the
experiment, we first computed the ks-test statistic between the data
(the average partial distance data) and the random order distribution
and the first-two optimal distribution. Since smaller ks-statistics
indicate a closer match between the distributions, we then took the
ratio of the ks-statistics (random over first two-optimal). Values less
than one indicate that the data are more consistent with random than
optimal responding. Values greater than one indicate that the data are
more consistent with optimal rather than random responding.</p>
<p><img src="figure/analysis_exp1_labelled_nodelay.Rmd/sampling_dist-1.png" width="672" style="display: block; margin: auto;" /><img src="figure/analysis_exp1_labelled_nodelay.Rmd/sampling_dist-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>This figure efficiently summarises the main result: responding is
more optimal in the fixed deadline condition particularly during the
last ten trials; in the random deadline conditions, responding was
closer to a random sampling distribution than to an optimal sampling
distribution.</p>
</div>
<div id="selection-choice-rts" class="section level2">
<h2>Selection Choice RTs</h2>
<table>
<caption>Mean RTs for each scheduling selection</caption>
<thead>
<tr class="header">
<th align="left">condition</th>
<th align="left">phase</th>
<th align="right">mrt_sel1</th>
<th align="right">mrt_sel2</th>
<th align="right">mrt_sel3</th>
<th align="right">mrt_sel4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">fixed</td>
<td align="left">untimed</td>
<td align="right">1521</td>
<td align="right">1319</td>
<td align="right">1054</td>
<td align="right">967</td>
</tr>
<tr class="even">
<td align="left">fixed</td>
<td align="left">deadline</td>
<td align="right">734</td>
<td align="right">697</td>
<td align="right">673</td>
<td align="right">639</td>
</tr>
<tr class="odd">
<td align="left">random</td>
<td align="left">untimed</td>
<td align="right">1856</td>
<td align="right">1439</td>
<td align="right">1217</td>
<td align="right">1031</td>
</tr>
<tr class="even">
<td align="left">random</td>
<td align="left">deadline</td>
<td align="right">920</td>
<td align="right">762</td>
<td align="right">706</td>
<td align="right">636</td>
</tr>
</tbody>
</table>
<!-- ## Alternative response strategies -->
<!-- An alternative possible strategy involves selecting RDKs based on spatial position. One salient strategy would be to start with a random RDK and then select the remaining tasks in clockwise and anti-clockwise order.  -->
<!-- The following plot shows the distribution of participants' spatial strategy use. Higher proportions indicate responses which are more consistent with a spatial strategy. These figures indicate that most participants do not use a spatial strategy. when difficulty is maintained in a fixed location, two groups emerge under a deadline: those who do not use a spatial strategy, though there is a slightly higher frequency of spatial strategy use in the random condition. -->
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.1.3 (2022-03-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19042)

Matrix products: default

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252   
[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                      
[5] LC_TIME=English_Australia.1252    

attached base packages:
[1] stats4    grid      stats     graphics  grDevices utils     datasets 
[8] methods   base     

other attached packages:
 [1] pmr_1.2.5.1       jpeg_0.1-9        rstatix_0.7.0     lme4_1.1-29      
 [5] Matrix_1.4-0      png_0.1-7         reshape2_1.4.4    knitr_1.38       
 [9] hrbrthemes_0.8.0  english_1.2-6     gtools_3.9.2      DescTools_0.99.45
[13] forcats_0.5.1     stringr_1.4.0     dplyr_1.0.8       purrr_0.3.4      
[17] readr_2.1.2       tidyr_1.2.0       tibble_3.1.6      ggplot2_3.3.5    
[21] tidyverse_1.3.1   workflowr_1.7.0  

loaded via a namespace (and not attached):
 [1] minqa_1.2.4       colorspace_2.0-3  ellipsis_0.3.2    class_7.3-20     
 [5] rprojroot_2.0.3   fs_1.5.2          gld_2.6.5         rstudioapi_0.13  
 [9] proxy_0.4-27      farver_2.1.0      fansi_1.0.3       mvtnorm_1.1-3    
[13] lubridate_1.8.0   xml2_1.3.3        splines_4.1.3     extrafont_0.18   
[17] rootSolve_1.8.2.3 jsonlite_1.8.0    nloptr_2.0.0      broom_0.8.0      
[21] Rttf2pt1_1.3.10   dbplyr_2.1.1      compiler_4.1.3    httr_1.4.2       
[25] backports_1.4.1   assertthat_0.2.1  fastmap_1.1.0     cli_3.2.0        
[29] later_1.3.0       htmltools_0.5.2   tools_4.1.3       gtable_0.3.0     
[33] glue_1.6.2        lmom_2.9          Rcpp_1.0.8.3      carData_3.0-5    
[37] cellranger_1.1.0  jquerylib_0.1.4   vctrs_0.4.1       nlme_3.1-155     
[41] extrafontdb_1.0   xfun_0.30         ps_1.6.0          rvest_1.0.2      
[45] lifecycle_1.0.1   getPass_0.2-2     MASS_7.3-55       scales_1.2.0     
[49] hms_1.1.1         promises_1.2.0.1  expm_0.999-6      yaml_2.3.5       
[53] Exact_3.1         gdtools_0.2.4     sass_0.4.1        stringi_1.7.6    
[57] highr_0.9         e1071_1.7-11      boot_1.3-28       rlang_1.0.2      
[61] pkgconfig_2.0.3   systemfonts_1.0.4 evaluate_0.15     lattice_0.20-45  
[65] labeling_0.4.2    processx_3.5.3    tidyselect_1.1.2  plyr_1.8.7       
[69] magrittr_2.0.3    R6_2.5.1          generics_0.1.2    DBI_1.1.2        
[73] pillar_1.7.0      haven_2.5.0       whisker_0.4       withr_2.5.0      
[77] abind_1.4-5       modelr_0.1.8      crayon_1.5.1      car_3.0-12       
[81] utf8_1.2.2        tzdb_0.3.0        rmarkdown_2.13    readxl_1.4.0     
[85] data.table_1.14.2 callr_3.7.0       git2r_0.30.1      reprex_2.0.1     
[89] digest_0.6.29     httpuv_1.6.5      munsell_0.5.0     bslib_0.3.1      </code></pre>
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Throughout, we infer significance by examining whether 2
<span class="math inline">\(\times\)</span> SE includes 0.<a
href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>We compared three models: (1) a standard linear
regression model with location condition, deadline, and their
interaction as factors (BIC = 7381.32) ; (2) a multilevel regression
model with an additional random intercept for each subject (BIC =
6461.97); and (3) a multilevel regression with a random intercept and
random deadline coefficient for each subject (BIC = 6225.19). The third
model was preferred on a BIC basis; hence, we report the details of that
model only.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
